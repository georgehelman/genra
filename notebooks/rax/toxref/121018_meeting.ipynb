{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import sys\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP = '/'.join(os.getcwd().split('/')[:-3])+'/'\n",
    "LIB = TOP+'lib'\n",
    "if not LIB in sys.path: \n",
    "    sys.path.insert(0,LIB)\n",
    "\n",
    "DAT_DIR = TOP + 'data/toxref/'\n",
    "FIG_DIR = TOP + 'figs/toxref/'\n",
    "\n",
    "from rax.genrapred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongocon=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_dev_v4\")\n",
    "DB=mongocon['genra_dev_v4']\n",
    "dsstox=DB['compound']\n",
    "toxref=DB['toxrefdb2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worthy(pdobject):\n",
    "    if isinstance(pdobject,pd.core.series.Series):\n",
    "        pdobject=pdobject[pd.notnull(pdobject)]\n",
    "        pdobject=pdobject[pdobject!=np.inf]\n",
    "        return pdobject\n",
    "    elif isinstance(pdobject,pd.core.frame.DataFrame):\n",
    "        pdobject=pdobject[pdobject.notnull().all(axis='columns')]\n",
    "        pdobject=pdobject[(pdobject!=np.inf).all(axis=1)]\n",
    "        return pdobject\n",
    "\n",
    "def wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)\n",
    "\n",
    "def exact_k_wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if len(df)<k:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)\n",
    "\n",
    "def wtvar(df,name,k):\n",
    "    df=df[(df[name].notnull()) & (df[name]!=np.inf)].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return sum([weights[i]**2*values[i] for i in range(len(values))])/sum(weights)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "ks=range(1,20)\n",
    "ss=[round(s/20,2) for s in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chemical_pod_record(document):\n",
    "    pods=document['pods']\n",
    "    for pod in pods:\n",
    "        pod['dsstox_sid']=document['dsstox_sid']\n",
    "    return pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def study_pod_record(document):\n",
    "    studies=document['studies']\n",
    "    for study in studies:\n",
    "        study['dsstox_sid']=document['dsstox_sid']\n",
    "    return studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def r2_plot(pred_df):\n",
    "    i=1\n",
    "    f=plt.figure(figsize=(12,12))\n",
    "    f.suptitle('Mean Aggregation Predictions')\n",
    "    for category in categories:\n",
    "        plt.subplot(2,2,i)\n",
    "        i+=1\n",
    "        df=pred_df[[category,category+'_p']]\n",
    "        df=df[df.notnull().all(axis='columns')]\n",
    "        df=df[(df!=np.inf).all(axis=1)]\n",
    "        plt.scatter(df[category],df[category+'_p'])\n",
    "        plt.title(category+ ' study predictions')\n",
    "        plt.xlabel('True')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.9),xycoords='axes fraction')\n",
    "    plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "    plt.savefig(FIG_DIR+'example_fit_mean')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.ticker import NullFormatter\n",
    "def simresplot(accuracy_df):\n",
    "    df=accuracy_df.copy()[['av_sim','systemic_accuracy']]\n",
    "    df=df.loc[plot_worthy(df['systemic_accuracy']).index.values]\n",
    "    x=df['av_sim']\n",
    "    y=df['systemic_accuracy']\n",
    "\n",
    "    nullfmt=NullFormatter()\n",
    "    left,width=.1,.65\n",
    "    bottom, height = .1,.65\n",
    "    bottom_h = bottom + height +.02\n",
    "    left_h = left + width + .02\n",
    "    rect_scatter = [left,bottom,width,height]\n",
    "    rect_histx = [left,bottom_h,width,.2]\n",
    "    rect_histy = [left_h,bottom,.2,height]\n",
    "    plt.figure(1, figsize=(8,8))\n",
    "\n",
    "    axScatter=plt.axes(rect_scatter)\n",
    "    axHistx = plt.axes(rect_histx)\n",
    "    axHisty = plt.axes(rect_histy)\n",
    "    axHistx.xaxis.set_major_formatter(nullfmt)\n",
    "    axHisty.yaxis.set_major_formatter(nullfmt)\n",
    "\n",
    "    axScatter.scatter(x,y,label=\"\")\n",
    "    X=np.array([x**i for i in range(0,2)]).T\n",
    "    order3=LinearRegression()\n",
    "    order3.fit(X,y)\n",
    "    x_space=np.linspace(0,1,100)\n",
    "    x_dummy=np.array([x_space**i for i in range(0,2)]).T\n",
    "    axScatter.plot(x_space,order3.predict(x_dummy),color='orange',linestyle='--',linewidth=3, label='fit')\n",
    "    axScatter.legend(loc='upper left')\n",
    "\n",
    "    axHistx.hist(x)\n",
    "    axHisty.hist(y,orientation='horizontal')\n",
    "    axHistx.set_xlim(axScatter.get_xlim())\n",
    "    axHisty.set_ylim(axScatter.get_ylim())\n",
    "\n",
    "    axHistx.set_title('Systemic residual vs similarity')\n",
    "    axScatter.set_xlabel('Average similarity across neighborhood')\n",
    "    axScatter.set_ylabel('Systemic residual')\n",
    "    plt.savefig(FIG_DIR+'simvsres',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_pods_df=pd.DataFrame([pod for document in toxref.find() for pod in chemical_pod_record(document)])\n",
    "str(len(chemical_pods_df)) + ' total chemical level PODs'\n",
    "chemical_pods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_pods_df=pd.DataFrame([study for document in toxref.find() for study in study_pod_record(document)])\n",
    "str(len(study_pods_df)) + ' total study level PODs'\n",
    "study_pods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_pods_df['study_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_loaels=chemical_pods_df[chemical_pods_df['pod_type']=='loael']\n",
    "study_loaels=study_pods_df[study_pods_df['pod_type']=='loael']\n",
    "str(len(chemical_loaels)) + ' chemical level LOAELs'\n",
    "str(len(study_loaels)) + ' study level LOAELs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=list(chemical_pods_df['endpoint_category'].unique())\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_loaels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chemical level POD munging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_loaels['pod_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No obvious way to convert units because we do not have species info\n",
    "chemical_loaels=chemical_loaels.loc[chemical_loaels.pod_unit=='mg/kg/day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_loaels['qualifier'].value_counts()\n",
    "print('Why = in quotations??')\n",
    "chemical_loaels.loc[chemical_loaels.qualifier==\"'='\",'qualifier']='='\n",
    "print('Fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to convert to log molar\n",
    "chemical_sids=list(chemical_loaels['dsstox_sid'].unique())\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':chemical_sids}})}\n",
    "chemical_loaels['mol_weight']=chemical_loaels['dsstox_sid'].map(weights)\n",
    "chemical_loaels['pod_value_LM']=-np.log10(chemical_loaels['pod_value']/chemical_loaels['mol_weight']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_loaels.to_csv(DAT_DIR+'chemical_loaels.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chemical_loaels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Study level POD munging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels['admin_route'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels=study_loaels[study_loaels['admin_route']=='Oral']\n",
    "print('Only looking at oral studies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels['pod_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels.loc[study_loaels.pod_unit=='ppm']['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels.loc[study_loaels.pod_unit=='%']['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit conversions\n",
    "from __future__ import division\n",
    "study_loaels.loc[(study_loaels['pod_unit']=='ppm') & (study_loaels['species']=='rat'),'pod_value']*=.05\n",
    "study_loaels.loc[(study_loaels['pod_unit']=='ppm') & (study_loaels['species']=='mouse'),'pod_value']*=.15\n",
    "study_loaels.loc[(study_loaels['pod_unit'] =='ppm') & (study_loaels['species']=='dog'),'pod_value']*=.075\n",
    "study_loaels.loc[(study_loaels['pod_unit']=='ppm') & (study_loaels['species']=='rabbit'),'pod_value']*=.03\n",
    "study_loaels.loc[(study_loaels['pod_unit']=='%'),'pod_value']*=10000*.15\n",
    "study_loaels.loc[(study_loaels['pod_unit']=='mg/kg/wk'),'pod_value']*=(1/7)\n",
    "study_loaels.loc[(study_loaels['pod_unit']=='mg/rat/day'),'pod_value']*=(1/.4)\n",
    "study_loaels['pod_unit']='mg/kg/day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels['qualifier'].value_counts()\n",
    "print('Why = in quotations??')\n",
    "study_loaels.loc[study_loaels.qualifier==\"'='\",'qualifier']='='\n",
    "print('Fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to convert to log molar\n",
    "study_sids=list(study_loaels['dsstox_sid'].unique())\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':study_sids}})}\n",
    "study_loaels['mol_weight']=study_loaels['dsstox_sid'].map(weights)\n",
    "study_loaels['pod_value_LM']=-np.log10(study_loaels['pod_value']/study_loaels['mol_weight']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels.to_csv(DAT_DIR+'study_loaels.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chemical_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EDA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([plot_worthy(chemical_loaels['pod_value']),plot_worthy(study_loaels['pod_value'])],bins=20,histtype='step',label=['chemical','study'])\n",
    "plt.legend(prop={'size':12})\n",
    "plt.title('POD value histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([plot_worthy(chemical_loaels['pod_value_LM']),plot_worthy(study_loaels['pod_value_LM'])],bins=20,histtype='step',label=['chemical','study'])\n",
    "plt.legend(prop={'size':12})\n",
    "plt.title('Log molar POD value histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data=[plot_worthy(chemical_loaels.loc[chemical_loaels.qualifier=='=','pod_value_LM']),plot_worthy(chemical_loaels.loc[chemical_loaels.qualifier=='>','pod_value_LM'])]\n",
    "plt.hist(plot_data,bins=20,histtype='step',label=['=','>'])\n",
    "plt.legend(prop={'size':12})\n",
    "plt.title('Chemical LOAELs by qualifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data=[plot_worthy(study_loaels.loc[study_loaels.qualifier=='=','pod_value_LM']),plot_worthy(study_loaels.loc[study_loaels.qualifier=='>','pod_value_LM'])]\n",
    "plt.hist(plot_data,histtype='step',bins=20,label=['=','>'])\n",
    "plt.legend(prop={'size':12})\n",
    "plt.title('Chemical LOAELs by qualifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chemical level POD fit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_neighbors_l=[]\n",
    "for sid in chemical_sids:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=chemical_sids,DB=DB)\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        chemical_neighbors_l=chemical_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_agg_mean=chemical_loaels.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_neighbors_mean=pd.DataFrame(chemical_neighbors_l)\n",
    "chemical_neighbors_mean=chemical_neighbors_mean[chemical_neighbors_mean['target_sid']!=chemical_neighbors_mean['neighbor_sid']]\n",
    "chemical_neighbors_mean=chemical_neighbors_mean.merge(chemical_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "chemical_neighbors_mean=chemical_neighbors_mean.sort_values('jaccard',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_neighbors_mean.to_csv(DAT_DIR+'chemical_neighbors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_predictions_mean_dict={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in chemical_neighbors_mean.groupby('target_sid'):\n",
    "    chemical_predictions_mean_dict[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_predictions_mean=pd.DataFrame(chemical_predictions_mean_dict.values(),index=chemical_predictions_mean_dict.keys())\n",
    "chemical_predictions_mean=chemical_predictions_mean.merge(chemical_agg_mean,right_index=True,left_index=True)\n",
    "chemical_predictions_mean.to_csv(DAT_DIR+'chemical_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_plot(chemical_predictions_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "av_sims={}\n",
    "for sid,group in chemical_neighbors_mean.groupby('target_sid'):\n",
    "    av_sim=group.iloc[0:2]['jaccard'].mean()\n",
    "    av_sims[sid]=av_sim\n",
    "chemical_accuracy=chemical_predictions_mean.copy()\n",
    "chemical_accuracy['systemic_accuracy']=abs(chemical_accuracy['systemic']-chemical_accuracy['systemic_p'])\n",
    "chemical_accuracy['av_sim']=chemical_accuracy.index.map(av_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simresplot(chemical_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Study level POD fit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_neighbors_l=[]\n",
    "for sid in study_sids:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=study_sids,DB=DB)\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        study_neighbors_l=study_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_agg_mean=study_loaels.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_neighbors_mean=pd.DataFrame(study_neighbors_l)\n",
    "study_neighbors_mean=study_neighbors_mean[study_neighbors_mean['target_sid']!=study_neighbors_mean['neighbor_sid']]\n",
    "study_neighbors_mean=study_neighbors_mean.merge(study_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "study_neighbors_mean=study_neighbors_mean.sort_values('jaccard',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_neighbors_mean.to_csv(DAT_DIR+'study_neighbors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_predictions_mean_dict={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in study_neighbors_mean.groupby('target_sid'):\n",
    "    study_predictions_mean_dict[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_predictions_mean=pd.DataFrame(study_predictions_mean_dict.values(),index=study_predictions_mean_dict.keys())\n",
    "study_predictions_mean=study_predictions_mean.merge(study_agg_mean,right_index=True,left_index=True)\n",
    "study_predictions_mean.to_csv(DAT_DIR+'study_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_plot(study_predictions_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Only = qualifier</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Chemical</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_loaels_equal=chemical_loaels.loc[chemical_loaels.qualifier=='=']\n",
    "chemical_loaels_equal['dsstox_sid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_sids_equal=list(chemical_loaels_equal['dsstox_sid'].unique())\n",
    "chemical_neighbors_equal_l=[]\n",
    "for sid in chemical_sids_equal:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=chemical_sids_equal,DB=DB)\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        chemical_neighbors_equal_l=chemical_neighbors_equal_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_agg_mean_equal=chemical_loaels_equal.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_neighbors_mean_equal=pd.DataFrame(chemical_neighbors_equal_l)\n",
    "chemical_neighbors_mean_equal=chemical_neighbors_mean_equal[chemical_neighbors_mean_equal['target_sid']!=chemical_neighbors_mean_equal['neighbor_sid']]\n",
    "chemical_neighbors_mean_equal=chemical_neighbors_mean_equal.merge(chemical_agg_mean_equal,left_on='neighbor_sid',right_index=True)\n",
    "chemical_neighbors_mean_equal=chemical_neighbors_mean_equal.sort_values('jaccard',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_neighbors_mean_equal.to_csv(DAT_DIR+'chemical_neighbors_equal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_predictions_mean_equal_dict={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in chemical_neighbors_mean_equal.groupby('target_sid'):\n",
    "    chemical_predictions_mean_equal_dict[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_predictions_mean_equal=pd.DataFrame(chemical_predictions_mean_equal_dict.values(),index=chemical_predictions_mean_equal_dict.keys())\n",
    "chemical_predictions_mean_equal=chemical_predictions_mean_equal.merge(chemical_agg_mean_equal,right_index=True,left_index=True)\n",
    "chemical_predictions_mean_equal.to_csv(DAT_DIR+'chemical_predictions_equal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_plot(chemical_predictions_mean_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Study</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_loaels_equal=study_loaels.loc[study_loaels.qualifier=='=']\n",
    "study_loaels_equal['dsstox_sid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sids_equal=list(study_loaels_equal['dsstox_sid'].unique())\n",
    "study_neighbors_equal_l=[]\n",
    "for sid in study_sids_equal:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=study_sids_equal,DB=DB)\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        study_neighbors_equal_l=study_neighbors_equal_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_agg_mean_equal=study_loaels_equal.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_neighbors_mean_equal=pd.DataFrame(study_neighbors_equal_l)\n",
    "study_neighbors_mean_equal=study_neighbors_mean_equal[study_neighbors_mean_equal['target_sid']!=study_neighbors_mean_equal['neighbor_sid']]\n",
    "study_neighbors_mean_equal=study_neighbors_mean_equal.merge(study_agg_mean_equal,left_on='neighbor_sid',right_index=True)\n",
    "study_neighbors_mean_equal=study_neighbors_mean_equal.sort_values('jaccard',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_neighbors_mean_equal.to_csv(DAT_DIR+'study_neighbors_equal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_predictions_mean_equal_dict={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in study_neighbors_mean_equal.groupby('target_sid'):\n",
    "    study_predictions_mean_equal_dict[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_predictions_mean_equal=pd.DataFrame(study_predictions_mean_equal_dict.values(),index=study_predictions_mean_equal_dict.keys())\n",
    "study_predictions_mean_equal=study_predictions_mean_equal.merge(study_agg_mean_equal,right_index=True,left_index=True)\n",
    "study_predictions_mean_equal.to_csv(DAT_DIR+'study_predictions_equal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_plot(study_predictions_mean_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Additional Covariates</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create stacked df (should have done this all along)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(DAT_DIR+'../../clusters.pkl') as f:\n",
    "    clusters=pkl.load(f)\n",
    "cluster_dict={cluster['cl_id']:cluster['chems'] for cluster in clusters}\n",
    "reverse_cluster_dict={dsstox_sid:clid for clid,list_of_sids in cluster_dict.iteritems() for dsstox_sid in list_of_sids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{'dsstox_sid':sid,'clid':clid} for sid,clid in reverse_cluster_dict.iteritems()]).to_csv(DAT_DIR+'cluster_membership.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_membership=pd.read_csv(DAT_DIR+'cluster_membership.csv')\n",
    "cluster_membership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_gridsearch_mrgn=pd.read_csv(DAT_DIR+'../toxref_ks_gridsearch_mrgn.csv',index_col=0)\n",
    "ks_gridsearch_mrgn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_ks_gridsearch_mrgn=pd.read_csv(DAT_DIR+'../toxref_exact_ks_gridsearch_mrgn.csv',index_col=0)\n",
    "exact_ks_gridsearch_mrgn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids=set(ks_gridsearch_mrgn['dsstox_sid'].unique())\n",
    "toxref_cluster_dict={clid:set(chems)&sids for clid,chems in cluster_dict.iteritems()}\n",
    "clusters_gt15={clid:chems for clid,chems in toxref_cluster_dict.iteritems() if len(chems)>15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "stacked_df=pd.DataFrame()\n",
    "for category in categories:\n",
    "    cat_df=ks_gridsearch_mrgn[[category,category+'_p','k','s','dsstox_sid']]\n",
    "    cat_df=cat_df.rename(columns={category:'true',category+'_p':'predicted'})\n",
    "    cat_df['endpoint_category']=category\n",
    "    stacked_df=stacked_df.append(cat_df)\n",
    "stacked_df=plot_worthy(stacked_df)\n",
    "stacked_df['cluster']=stacked_df['dsstox_sid'].map(reverse_cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "exactk_stacked_df=pd.DataFrame()\n",
    "for category in categories:\n",
    "    cat_df=exact_ks_gridsearch_mrgn[[category,category+'_p','k','s','dsstox_sid']]\n",
    "    cat_df=cat_df.rename(columns={category:'true',category+'_p':'predicted'})\n",
    "    cat_df['endpoint_category']=category\n",
    "    exactk_stacked_df=exactk_stacked_df.append(cat_df)\n",
    "exactk_stacked_df=plot_worthy(exactk_stacked_df)\n",
    "exactk_stacked_df['cluster']=exactk_stacked_df['dsstox_sid'].map(reverse_cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_stacked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cluster grid search</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Up to k</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_clusters={}\n",
    "for clid,chems in clusters_gt15.iteritems():\n",
    "    ks_clusters[clid]=np.full([len(ks),len(ss)],np.nan)\n",
    "    cluster_df=stacked_df.loc[stacked_df.dsstox_sid.isin(chems)]\n",
    "    for (k,s),group in cluster_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        ks_clusters[clid][k_index,s_index]=r2_score(group['true'],group['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "for clid,cluster_grid_r2 in ks_clusters.iteritems():\n",
    "    fig,ax=plt.subplots(figsize=(6,4),subplot_kw={'projection':'3d'})\n",
    "    ax.plot_surface(X,Y,cluster_grid_r2,cmap=plt.cm.coolwarm)\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "    ax.set_title('Cluster '+ clid )\n",
    "    ax.text2D(.75,.95,'n='+str(len(clusters_gt15[clid])),transform=ax.transAxes,fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cat_r2s=[]\n",
    "for (k,s,endpoint_category,clid),group in stacked_df.groupby(['k','s','endpoint_category','cluster']):\n",
    "    if len(group)<2:\n",
    "        continue\n",
    "    cluster_cat_r2s.append({'k':k,'s':s,'endpoint_category':endpoint_category,'clid':clid,'n':len(group),\\\n",
    "                           'r2':r2_score(group['true'],group['predicted'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cat_r2_df=pd.DataFrame(cluster_cat_r2s)\n",
    "cluster_cat_r2_df.head()\n",
    "cluster_cat_r2_df.to_csv(DAT_DIR+'cluster_ks_gridsearch_wo_restriction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cat_r2_df[(cluster_cat_r2_df.k==10) & (cluster_cat_r2_df.s==.5)].pivot_table(index='endpoint_category',columns='clid',values='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_ks=[]\n",
    "for (clid,endpoint_category),group in cluster_cat_r2_df.groupby(['clid','endpoint_category']):\n",
    "    max_row=group.loc[group['r2'].idxmax()]\n",
    "    optimal_ks.append({'clid':clid,'endpoint_category':endpoint_category,'k':max_row['k'],'s':max_row['s'],'n':max_row['n'],'r2':max_row['r2']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(optimal_ks).head()\n",
    "pd.DataFrame(optimal_ks).to_csv(DAT_DIR+'cluster_optimal_ks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exactk</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_cat_r2s=[]\n",
    "for (k,s,endpoint_category,clid),group in exactk_stacked_df.groupby(['k','s','endpoint_category','cluster']):\n",
    "    if len(group)<2:\n",
    "        continue\n",
    "    exactk_cluster_cat_r2s.append({'k':k,'s':s,'endpoint_category':endpoint_category,'clid':clid,'n':len(group),\\\n",
    "                           'r2':r2_score(group['true'],group['predicted'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_cat_r2_df=pd.DataFrame(exactk_cluster_cat_r2s)\n",
    "exactk_cluster_cat_r2_df.head()\n",
    "exactk_cluster_cat_r2_df.to_csv(DAT_DIR+'exactk_cluster_ks_gridsearch_wo_restriction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_optimal_ks=[]\n",
    "for (clid,endpoint_category),group in exactk_cluster_cat_r2_df.groupby(['clid','endpoint_category']):\n",
    "    max_row=group.loc[group['r2'].idxmax()]\n",
    "    exactk_optimal_ks.append({'clid':clid,'endpoint_category':endpoint_category,'k':max_row['k'],'s':max_row['s'],'n':max_row['n'],'r2':max_row['r2']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(exactk_optimal_ks).head()\n",
    "pd.DataFrame(exactk_optimal_ks).to_csv(DAT_DIR+'exactk_cluster_optimal_ks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows',None):\n",
    "    opt_df=pd.DataFrame(exactk_optimal_ks)\n",
    "    opt_df[opt_df['n']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nandata=pd.DataFrame(\\\n",
    "                     [{'clid':clid,'k':k,'s':s,'endpoint_category':endpoint_category,'r2':np.nan}\\\n",
    "                      for clid in exactk_cluster_cat_r2_df['clid'].unique()\\\n",
    "                      for k in ks\\\n",
    "                      for s in ss\\\n",
    "                      for endpoint_category in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_cat_r2_df_expanded=exactk_cluster_cat_r2_df.merge(nandata,how='right',on=['k','s','endpoint_category','clid'],suffixes=('','_drop'))\n",
    "del exactk_cluster_cat_r2_df_expanded['r2_drop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for clid,group in exactk_cluster_cat_r2_df_expanded.groupby('clid'):\n",
    "    cluster_r2s=group.pivot_table(index='k',columns='s',values='r2',dropna=False)\n",
    "    ax=sns.heatmap(cluster_r2s,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1)\n",
    "    ax.invert_yaxis()\n",
    "    plt.title('Cluster ' + clid)\n",
    "    plt.xlabel('s')\n",
    "    plt.ylabel('k')\n",
    "    plt.savefig(FIG_DIR+'cluster_heatmaps/cluster'+clid+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deduped Study Comparison</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduped_study_pod_record(document):\n",
    "    studies=document['deduped_studies']\n",
    "    for study in studies:\n",
    "        study['dsstox_sid']=document['dsstox_sid']\n",
    "    return studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_pods_df=pd.DataFrame([study for document in toxref.find() for study in deduped_study_pod_record(document)])\n",
    "str(len(deduped_study_pods_df)) + ' total study level PODs'\n",
    "deduped_study_pods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels=deduped_study_pods_df[deduped_study_pods_df['pod_type']=='loael']\n",
    "str(len(deduped_study_loaels)) + ' deduped study level LOAELs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels['admin_route'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels=deduped_study_loaels[deduped_study_loaels['admin_route']=='Oral']\n",
    "print('Only looking at oral studies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels['pod_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels.loc[deduped_study_loaels.pod_unit=='ppm']['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels.loc[deduped_study_loaels.pod_unit=='%']['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit conversions\n",
    "from __future__ import division\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit']=='ppm') & (deduped_study_loaels['species']=='rat'),'pod_value']*=.05\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit']=='ppm') & (deduped_study_loaels['species']=='mouse'),'pod_value']*=.15\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit'] =='ppm') & (deduped_study_loaels['species']=='dog'),'pod_value']*=.075\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit']=='ppm') & (deduped_study_loaels['species']=='rabbit'),'pod_value']*=.03\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit']=='%'),'pod_value']*=10000*.15\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit']=='mg/kg/wk'),'pod_value']*=(1/7)\n",
    "deduped_study_loaels.loc[(deduped_study_loaels['pod_unit']=='mg/rat/day'),'pod_value']*=(1/.4)\n",
    "deduped_study_loaels['pod_unit']='mg/kg/day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels['qualifier'].value_counts()\n",
    "print('Why = in quotations??')\n",
    "deduped_study_loaels.loc[deduped_study_loaels.qualifier==\"'='\",'qualifier']='='\n",
    "print('Fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to convert to log molar\n",
    "deduped_study_sids=list(deduped_study_loaels['dsstox_sid'].unique())\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':deduped_study_sids}})}\n",
    "deduped_study_loaels['mol_weight']=deduped_study_loaels['dsstox_sid'].map(weights)\n",
    "deduped_study_loaels['pod_value_LM']=-np.log10(deduped_study_loaels['pod_value']/deduped_study_loaels['mol_weight']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_loaels.to_csv(DAT_DIR+'deduped_study_loaels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([plot_worthy(chemical_loaels['pod_value']),plot_worthy(study_loaels['pod_value']),plot_worthy(deduped_study_loaels['pod_value'])],bins=20,histtype='step',label=['chemical','study','deduped'])\n",
    "plt.legend(prop={'size':12})\n",
    "plt.title('POD value histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([plot_worthy(chemical_loaels['pod_value_LM']),plot_worthy(study_loaels['pod_value_LM']),plot_worthy(deduped_study_loaels['pod_value_LM'])],bins=20,histtype='step',label=['chemical','study','deduped'])\n",
    "plt.legend(prop={'size':12})\n",
    "plt.title('Log molar POD value histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_neighbors_l=[]\n",
    "for sid in study_sids:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=study_sids,DB=DB)\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        deduped_study_neighbors_l=deduped_study_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_agg_mean=deduped_study_loaels.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_neighbors_mean=pd.DataFrame(deduped_study_neighbors_l)\n",
    "deduped_study_neighbors_mean=deduped_study_neighbors_mean[deduped_study_neighbors_mean['target_sid']!=deduped_study_neighbors_mean['neighbor_sid']]\n",
    "deduped_study_neighbors_mean=deduped_study_neighbors_mean.merge(deduped_study_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "deduped_study_neighbors_mean=deduped_study_neighbors_mean.sort_values('jaccard',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_neighbors_mean.to_csv(DAT_DIR+'deduped_study_neighbors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_predictions_mean_dict={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in deduped_study_neighbors_mean.groupby('target_sid'):\n",
    "    deduped_study_predictions_mean_dict[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_study_predictions_mean=pd.DataFrame(deduped_study_predictions_mean_dict.values(),index=deduped_study_predictions_mean_dict.keys())\n",
    "deduped_study_predictions_mean=deduped_study_predictions_mean.merge(deduped_study_agg_mean,right_index=True,left_index=True)\n",
    "deduped_study_predictions_mean.to_csv(DAT_DIR+'deduped_study_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_plot(deduped_study_predictions_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
