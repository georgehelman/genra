{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import sys\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP = '/'.join(os.getcwd().split('/')[:-3])+'/'\n",
    "LIB = TOP+'lib'\n",
    "if not LIB in sys.path: \n",
    "    sys.path.insert(0,LIB)\n",
    "\n",
    "DAT_DIR = TOP + 'data/toxref/'\n",
    "FIG_DIR = TOP + 'figs/toxref/'\n",
    "\n",
    "from rax.genrapred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongocon=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_dev_v4\")\n",
    "DB=mongocon['genra_dev_v4']\n",
    "dsstox=DB['compound']\n",
    "toxref=DB['toxrefdb2'] #Do not change! toxrefdb2 is the correct collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worthy(pdobject):\n",
    "    if isinstance(pdobject,pd.core.series.Series):\n",
    "        pdobject=pdobject[pd.notnull(pdobject)]\n",
    "        pdobject=pdobject[pdobject!=np.inf]\n",
    "        return pdobject\n",
    "    elif isinstance(pdobject,pd.core.frame.DataFrame):\n",
    "        pdobject=pdobject[pdobject.notnull().all(axis='columns')]\n",
    "        pdobject=pdobject[(pdobject!=np.inf).all(axis=1)]\n",
    "        return pdobject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>=s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_k_wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if len(df)<k:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtvar(df,name,k):\n",
    "    df=df[(df[name].notnull()) & (df[name]!=np.inf)].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return sum([weights[i]**2*values[i] for i in range(len(values))])/sum(weights)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "ks=range(1,20)\n",
    "ss=[round(s/20,2) for s in range(1,20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EDA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(toxref.count()) + ' total substances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pod_record(document):\n",
    "    pods=document['pods']\n",
    "    for pod in pods:\n",
    "        pod['dsstox_sid']=document['dsstox_sid']\n",
    "    return pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df=pd.DataFrame([pod for document in toxref.find() for pod in pod_record(document)])\n",
    "#pods_df=pods_df[pods_df['effect_profile_id']==2] #Turns out they all equal 2\n",
    "len(pods_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to convert to log molar\n",
    "sids=list(pods_df['dsstox_sid'].unique())\n",
    "print(str(len(sids)) + ' chemicals with POD values')\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':sids}})}\n",
    "pods_df['mol_weight']=pods_df['dsstox_sid'].map(weights)\n",
    "pods_df['pod_value_LM']=-np.log10(pods_df['pod_value']/pods_df['mol_weight']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_df=pods_df[pods_df['pod_type']=='loael']\n",
    "loael_df=loael_df[loael_df['pod_unit']=='mg/kg/day']\n",
    "loael_df.to_csv(DAT_DIR+'loael.csv',encoding='utf-8')\n",
    "print(str(len(loael_df))+ ' LOAEL values')\n",
    "print(str(loael_df['dsstox_sid'].nunique()) + ' chemicals with LOAEL values')\n",
    "print(str(loael_df[pd.notnull(loael_df['mol_weight'])]['dsstox_sid'].nunique())+' unique chemicals with mol weights from DSSTox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives number of unique chemicals having LOAEL values for each endpoint category\n",
    "loael_df.pivot_table(index='endpoint_category',values='dsstox_sid',aggfunc=lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find Neighbors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg=loael_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='min')\n",
    "loael_agg.to_csv(DAT_DIR+'loaelagg.csv',encoding='utf-8')\n",
    "loael_sids=list(set(loael_agg.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=list(loael_agg.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loael_neighbors_l=[]\n",
    "# for sid in loael_sids:\n",
    "#     sid_neighbors=searchCollByFP(sid,s0=.05,SID=loael_sids,DB=DB)\n",
    "#     if sid_neighbors:\n",
    "#         for neighbor in sid_neighbors:\n",
    "#             neighbor['target_sid']=sid\n",
    "#             neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "#         loael_neighbors_l=loael_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Min Agg</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loael_neighbors=pd.DataFrame(loael_neighbors_l)\n",
    "# loael_neighbors=loael_neighbors[loael_neighbors['target_sid']!=loael_neighbors['neighbor_sid']]\n",
    "# loael_neighbors=loael_neighbors.merge(loael_agg,left_on='neighbor_sid',right_index=True)\n",
    "# loael_neighbors=loael_neighbors.sort_values('jaccard',ascending=False)\n",
    "# loael_neighbors.to_csv(DAT_DIR+'loael_neighbors_mrgn.csv')\n",
    "# print(str(loael_neighbors['target_sid'].nunique()) + ' successfully found some neighbors')\n",
    "# loael_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors=pd.read_csv(DAT_DIR+'loael_neighbors_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors[loael_neighbors['target_sid']=='DTXSID3020621']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions={}\n",
    "# k=10\n",
    "# s=.05\n",
    "# for sid,group in loael_neighbors.groupby('target_sid'):\n",
    "#         predictions[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loael_predictions=pd.DataFrame(predictions.values(),index=predictions.keys())\n",
    "# loael_predictions=loael_predictions.merge(loael_agg,right_index=True,left_index=True)\n",
    "# print(str(len(loael_predictions))+' chemicals successfully predicted')\n",
    "# print(str(len(loael_df[loael_df['dsstox_sid'].isin(loael_predictions.index)])) + ' associated LOAEL values')\n",
    "# loael_predictions.to_csv(DAT_DIR+'loael_predictions_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_predictions=pd.read_csv(DAT_DIR+'loael_predictions_mrgn.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "plt.suptitle('Min Aggregation Prediction')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=loael_predictions[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mean Agg</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean=loael_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')\n",
    "loael_agg_sd=loael_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='std')\n",
    "loael_agg_sd=loael_agg_sd.loc[loael_agg_mean.index]\n",
    "loael_agg_mean.to_csv(DAT_DIR+'loael_agg_mean_mrgn.csv')\n",
    "loael_agg_sd.to_csv(DAT_DIR+'loael_agg_sd_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_mean=pd.DataFrame(loael_neighbors_l)\n",
    "loael_neighbors_mean=loael_neighbors_mean[loael_neighbors_mean['target_sid']!=loael_neighbors_mean['neighbor_sid']]\n",
    "loael_neighbors_mean=loael_neighbors_mean.merge(loael_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "loael_neighbors_mean=loael_neighbors_mean.sort_values('jaccard',ascending=False)\n",
    "loael_neighbors_mean.to_csv(DAT_DIR+'loael_neighbors_mean_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loael_neighbors_sd=pd.DataFrame(loael_neighbors_l)\n",
    "# loael_neighbors_sd=loael_neighbors_sd[loael_neighbors_sd['target_sid']!=loael_neighbors_sd['neighbor_sid']]\n",
    "# loael_neighbors_sd=loael_neighbors_sd.merge(loael_agg_sd,left_on='neighbor_sid',right_index=True)\n",
    "# loael_neighbors_sd=loael_neighbors_sd.loc[loael_neighbors_mean.index]\n",
    "# loael_neighbors_sd.to_csv(DAT_DIR+'loael_neighbors_sd_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean=pd.read_csv(DAT_DIR+'loael_agg_mean_mrgn.csv',index_col='dsstox_sid')\n",
    "loael_neighbors_mean=pd.read_csv(DAT_DIR+'loael_neighbors_mean_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_mean={}\n",
    "# k=10\n",
    "# s=.05\n",
    "# for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "#     predictions_mean[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_sd={}\n",
    "# k=10\n",
    "# for sid,group in loael_neighbors_sd.groupby('target_sid'):\n",
    "#     predictions_sd[sid]={category:wtvar(group,category,k) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loael_predictions_mean=pd.DataFrame(predictions_mean.values(),index=predictions_mean.keys())\n",
    "# loael_predictions_mean=loael_predictions_mean.merge(loael_agg_mean,right_index=True,left_index=True)\n",
    "# len(loael_predictions_mean)\n",
    "# loael_predictions_mean.head()\n",
    "# loael_predictions_mean.to_csv(DAT_DIR+'loael_predictions_mean_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_predictions_mean=pd.read_csv(DAT_DIR+'loael_predictions_mean_mrgn.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loael_predictions_sd=pd.DataFrame(predictions_sd.values(),index=predictions_sd.keys())\n",
    "# loael_predictions_sd=loael_predictions_sd.merge(loael_agg_sd,right_index=True,left_index=True)\n",
    "# loael_predictions_sd.to_csv(DAT_DIR+'loael_predictions_sd_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Mean Aggregation Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=loael_predictions_mean[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.9),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "av_sims={}\n",
    "for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "    av_sim=group.iloc[0:2]['jaccard'].mean()\n",
    "    av_sims[sid]=av_sim\n",
    "loael_accuracy=loael_predictions_mean.copy()\n",
    "loael_accuracy['systemic_accuracy']=abs(loael_accuracy['systemic']-loael_accuracy['systemic_p'])\n",
    "loael_accuracy['av_sim']=loael_accuracy.index.map(av_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "df=loael_accuracy.copy()[['av_sim','systemic_accuracy']]\n",
    "df=df.loc[plot_worthy(df['systemic_accuracy']).index.values]\n",
    "x=df['av_sim']\n",
    "y=df['systemic_accuracy']\n",
    "\n",
    "nullfmt=NullFormatter()\n",
    "left,width=.1,.65\n",
    "bottom, height = .1,.65\n",
    "bottom_h = bottom + height +.02\n",
    "left_h = left + width + .02\n",
    "rect_scatter = [left,bottom,width,height]\n",
    "rect_histx = [left,bottom_h,width,.2]\n",
    "rect_histy = [left_h,bottom,.2,height]\n",
    "plt.figure(1, figsize=(8,8))\n",
    "\n",
    "axScatter=plt.axes(rect_scatter)\n",
    "axHistx = plt.axes(rect_histx)\n",
    "axHisty = plt.axes(rect_histy)\n",
    "axHistx.xaxis.set_major_formatter(nullfmt)\n",
    "axHisty.yaxis.set_major_formatter(nullfmt)\n",
    "\n",
    "axScatter.scatter(x,y,label=\"\")\n",
    "X=np.array([x**i for i in range(0,2)]).T\n",
    "order3=LinearRegression()\n",
    "order3.fit(X,y)\n",
    "x_space=np.linspace(0,1,100)\n",
    "x_dummy=np.array([x_space**i for i in range(0,2)]).T\n",
    "axScatter.plot(x_space,order3.predict(x_dummy),color='orange',linestyle='--',linewidth=3, label='fit')\n",
    "axScatter.legend(loc='upper left')\n",
    "\n",
    "axHistx.hist(x)\n",
    "axHisty.hist(y,orientation='horizontal')\n",
    "axHistx.set_xlim(axScatter.get_xlim())\n",
    "axHisty.set_ylim(axScatter.get_ylim())\n",
    "\n",
    "axHistx.set_title('Systemic residual vs similarity')\n",
    "axScatter.set_xlabel('Average similarity across neighborhood')\n",
    "axScatter.set_ylabel('Systemic residual')\n",
    "plt.savefig(FIG_DIR+'simvsres',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Example Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt9=loael_neighbors_mean[loael_neighbors_mean['jaccard']>.9]['target_sid'].unique() #Targets with atleast 1 neighbors >.9\n",
    "len(loael_neighbors_mean['target_sid'].unique())\n",
    "len(gt9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(series):\n",
    "    diff=[abs(series[category]-series[category+'_p']) for category in categories if not np.isnan(series[category])]\n",
    "    return sum(diff)/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loael best results\n",
    "ranked_loaels=loael_predictions_mean.copy()\n",
    "ranked_loaels['rank']=ranked_loaels.apply(ranker,axis='columns')\n",
    "ranked_loaels=ranked_loaels.loc[gt9]\n",
    "ranked_loaels=ranked_loaels.sort_values('rank')\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':loael_sids}})}\n",
    "ranked_loaels['mol_weight']=ranked_loaels.index.map(weights)\n",
    "ranked_loaels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_loaels.loc['DTXSID5031131']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back(lm,weight):\n",
    "    return (10**-lm)*1000*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good prediction\n",
    "sid='DTXSID5020607'\n",
    "dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})\n",
    "row=loael_predictions_mean.loc[sid]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['developmental']))].iloc[0:10]\n",
    "nhood=loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['systemic']))].iloc[0:10]\n",
    "','.join(nhood['neighbor_sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad prediction\n",
    "sid='DTXSID2029612'\n",
    "dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})\n",
    "row=loael_predictions_mean.loc[sid]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "nhood=loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['systemic']))].iloc[0:10]\n",
    "','.join(nhood['neighbor_sid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genra_predict(ndf,tdf,category,k,s):\n",
    "    predictions={}\n",
    "    for sid,group in ndf.groupby(['target_sid']):\n",
    "        predictions[sid]=wtavg(group,category,k,s)\n",
    "    prediction_df=pd.DataFrame(predictions.values(),index=predictions.keys(),columns=[category+'_p'])\n",
    "    prediction_df=prediction_df.merge(tdf,right_index=True,left_index=True)\n",
    "    prediction_df=prediction_df[[category,category+'_p']]\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids=loael_neighbors['target_sid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "i=0\n",
    "q2s=[]\n",
    "r2s=[]\n",
    "k=10\n",
    "s=.05\n",
    "category='systemic'\n",
    "while i<500:\n",
    "    train,test=train_test_split(sids,test_size=.1)\n",
    "    train_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(train))]\n",
    "    train_predictions=plot_worthy(genra_predict(train_neighbors,loael_agg,category,k,s))\n",
    "    q2s.append(r2_score(train_predictions[category],train_predictions[category+'_p']))\n",
    "    test_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(test))]\n",
    "    test_predictions=plot_worthy(genra_predict(test_neighbors,loael_agg,category,k,s))\n",
    "    r2s.append(r2_score(test_predictions[category],test_predictions[category+'_p']))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(q2s,rwidth=.85)\n",
    "df=loael_predictions_mean[[category,category+'_p']]\n",
    "df=df[df.notnull().all(axis='columns')]\n",
    "df=df[(df!=np.inf).all(axis=1)]\n",
    "plt.axvline(x=r2_score(df['systemic'],df['systemic_p']),color='orange',label='Full Dataset')\n",
    "plt.xlabel('Q2 score')\n",
    "plt.title('Q2 scores for 100 90-10 train-test splits')\n",
    "plt.legend(loc='best',fontsize=11)\n",
    "plt.savefig(FIG_DIR+'q2hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r2s,rwidth=.85)\n",
    "df=loael_predictions_mean[[category,category+'_p']]\n",
    "df=df[df.notnull().all(axis='columns')]\n",
    "df=df[(df!=np.inf).all(axis=1)]\n",
    "plt.axvline(x=r2_score(df['systemic'],df['systemic_p']),color='orange',label='Full Dataset')\n",
    "plt.xlabel('R2 score')\n",
    "plt.title('R2 scores for 100 90-10 train-test splits')\n",
    "plt.legend(loc='best',fontsize=11)\n",
    "plt.savefig(FIG_DIR+'r2hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(r2s)\n",
    "np.median(q2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "percents=[n*.01 for n in range(1,26,1)]\n",
    "train_r2s=[]\n",
    "test_r2s=[]\n",
    "k=10\n",
    "s=.05\n",
    "for percent in percents:\n",
    "    train,test=train_test_split(sids,test_size=percent)\n",
    "    test_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(test))]\n",
    "    train_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(train))]\n",
    "    category='systemic'\n",
    "    test_df=plot_worthy(genra_predict(test_neighbors,loael_agg,category,k,s))\n",
    "    train_df=plot_worthy(genra_predict(train_neighbors,loael_agg,category,k,s))\n",
    "    test_r2s.append(r2_score(test_df[category],test_df[category+'_p']))\n",
    "    train_r2s.append(r2_score(train_df[category],train_df[category+'_p']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=plot_worthy(loael_predictions[['systemic','systemic_p']])\n",
    "r2_score(df['systemic'],df['systemic_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(test_r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(percents,test_r2s,label='test R2')\n",
    "ax.plot(percents,train_r2s,label='train R2')\n",
    "df=plot_worthy(loael_predictions[['systemic','systemic_p']])\n",
    "base_r2=r2_score(df['systemic'],df['systemic_p'])\n",
    "ax.axhline(y=base_r2,label='base R2',ls='--',color='black')\n",
    "ax.set_title('Learning Curve (Systemic)')\n",
    "ax.set_xlabel('Percent test set')\n",
    "ax.set_ylabel('R2')\n",
    "ax.legend(loc=0)\n",
    "plt.savefig(FIG_DIR+'learning_curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cluster Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_v3\")\n",
    "# DB2 = con['genra_v3']\n",
    "# clusters_collection=DB2['clusters1']\n",
    "# clusters=list(clusters_collection.find({},{'_id':0,'chems':1,'cl_id':1}))\n",
    "# cid_list=[chem for cluster in [cluster['chems'] for cluster in clusters] for chem in cluster]\n",
    "# cid_to_sid={record['dsstox_cid']:record['dsstox_sid'] for record in dsstox.find({'dsstox_cid':{'$in':cid_list}})}\n",
    "# for cluster in clusters:\n",
    "#     cluster['chems']=[cid_to_sid[cid] for cid in cluster['chems'] if cid in cid_to_sid.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open(DAT_DIR+'clusters.pkl','w') as f:\n",
    "#     pkl.dump(clusters,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(DAT_DIR+'../clusters.pkl') as f:\n",
    "    clusters=pkl.load(f)\n",
    "cluster_dict={cluster['cl_id']:cluster['chems'] for cluster in clusters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without restricting neighbors to be in same cluster\n",
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "r2s=[]\n",
    "for cluster in clusters:\n",
    "    f=plt.figure(figsize=(12,300))\n",
    "    chems=cluster['chems']\n",
    "    try:\n",
    "        df=loael_predictions_mean.loc[chems]\n",
    "    except:\n",
    "        continue    \n",
    "    df=df[['systemic','systemic_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    plt.subplot(50,2,i)\n",
    "    i+=1\n",
    "    plt.scatter(df['systemic'],df['systemic_p'])\n",
    "    ax_min=df.values.min()-.1\n",
    "    ax_max=df.values.max()+.1\n",
    "    plt.xlim(ax_min,ax_max)\n",
    "    plt.ylim(ax_min,ax_max)\n",
    "    plt.title('Cluster ' + str(cluster['cl_id']) + ' systemic LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df['systemic'],df['systemic_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "    plt.annotate('n='+str(len(df)),xy=(.8,-.2),xycoords='axes fraction')\n",
    "    r2s.append({'cl_id':cluster['cl_id'],'R2':r2_score(df['systemic'],df['systemic_p']),'size':len(df)})\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_r2_df=pd.DataFrame(r2s)\n",
    "loael_r2_df=loael_r2_df.sort_values('R2',ascending=False)\n",
    "loael_r2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_r2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within cluster predictions for up to k\n",
    "cluster_predictions=[]\n",
    "for k in ks:\n",
    "    for s in ss: \n",
    "        for cluster in clusters:\n",
    "            clid=int(cluster['cl_id'])\n",
    "            chems=cluster['chems']\n",
    "            cluster_df=loael_neighbors_mean[(loael_neighbors_mean['target_sid'].isin(chems)) & loael_neighbors_mean['neighbor_sid'].isin(chems)]\n",
    "            for sid,group in cluster_df.groupby('target_sid'):\n",
    "                prediction={category+'_p':wtavg(group,category,k,s) for category in categories}\n",
    "                prediction['dsstox_sid']=sid\n",
    "                prediction['cluster']=clid\n",
    "                prediction['k']=k\n",
    "                prediction['s']=s\n",
    "                prediction['cluster']=cluster['cl_id']\n",
    "                cluster_predictions.append(prediction)\n",
    "cluster_prediction_df=pd.DataFrame(cluster_predictions)\n",
    "cluster_prediction_df=cluster_prediction_df.merge(loael_agg_mean,left_on='dsstox_sid',right_index=True)\n",
    "cluster_prediction_df.to_csv(DAT_DIR+'cluster_ks_gridsearch_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within cluster predictions for exactk\n",
    "exactk_cluster_predictions=[]\n",
    "for k in ks:\n",
    "    for s in ss:\n",
    "        for cluster in clusters:\n",
    "            clid=int(cluster['cl_id'])\n",
    "            chems=cluster['chems']\n",
    "            cluster_df=loael_neighbors_mean[(loael_neighbors_mean['target_sid'].isin(chems)) & loael_neighbors_mean['neighbor_sid'].isin(chems)]\n",
    "            for sid,group in cluster_df.groupby('target_sid'):\n",
    "                prediction={category+'_p':exact_k_wtavg(group,category,k,s) for category in categories}\n",
    "                prediction['dsstox_sid']=sid\n",
    "                prediction['cluster']=clid\n",
    "                prediction['k']=k\n",
    "                prediction['s']=s\n",
    "                prediction['cluster']=cluster['cl_id']\n",
    "                exactk_cluster_predictions.append(prediction)\n",
    "exactk_cluster_prediction_df=pd.DataFrame(exactk_cluster_predictions)\n",
    "exactk_cluster_prediction_df=exactk_cluster_prediction_df.merge(loael_agg_mean,left_on='dsstox_sid',right_index=True)\n",
    "exactk_cluster_prediction_df.to_csv(DAT_DIR+'exactk_cluster_ks_gridsearch_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df=pd.read_csv(DAT_DIR+'cluster_ks_gridsearch_mrgn.csv')\n",
    "exactk_cluster_prediction_df=pd.read_csv(DAT_DIR+'exactk_cluster_ks_gridsearch_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With restricting predictions to within cluster for k=10 and s=.05 (systemic)\n",
    "i=1\n",
    "within_r2s=[]\n",
    "f=plt.figure(figsize=(12,300))\n",
    "for cluster in clusters:\n",
    "    chems=cluster['chems']\n",
    "    k=10\n",
    "    s=.05\n",
    "    cluster_df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems)) &\\\n",
    "                                    (cluster_prediction_df['k']==k) & (cluster_prediction_df['s']==s)]\n",
    "    cluster_df=cluster_df[['systemic','systemic_p']]\n",
    "    cluster_df=plot_worthy(cluster_df)\n",
    "    if cluster_df.empty:\n",
    "        continue\n",
    "    plt.subplot(50,2,i)\n",
    "    i+=1\n",
    "    plt.scatter(cluster_df['systemic_p'],cluster_df['systemic'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Cluster ' + str(cluster['cl_id']) + ' systemic LOAEL Predictions')\n",
    "    plt.annotate('R2='+str(round(r2_score(cluster_df['systemic'],cluster_df['systemic_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "    plt.annotate('n='+str(len(cluster_df)),xy=(.8,-.2),xycoords='axes fraction')\n",
    "    within_r2s.append({'cl_id':cluster['cl_id'],'R2':r2_score(cluster_df['systemic'],cluster_df['systemic_p']),'size':len(cluster_df)})\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_r2_df=pd.DataFrame(within_r2s)\n",
    "within_r2_df=within_r2_df.sort_values('R2',ascending=False)\n",
    "r2_df=within_r2_df.merge(loael_r2_df,on='cl_id',suffixes=('_within',''))\n",
    "r2_df['comp']=(r2_df['R2_within']>r2_df['R2'])*1\n",
    "r2_df=r2_df.set_index('cl_id')\n",
    "r2_df=r2_df.sort_values(['R2'],ascending=False)\n",
    "sum(r2_df['comp'])\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    r2_df\n",
    "r2_df.to_csv(DAT_DIR+'r2s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_gt_5=r2_df[r2_df['size']>=5]\n",
    "plt.hist(r2_gt_5['R2'])\n",
    "plt.title('Systemic R2s for clusters with size>5 without restriction')\n",
    "plt.xlabel('R2')\n",
    "plt.show()\n",
    "plt.hist(r2_gt_5['R2_within'])\n",
    "plt.title('Systemic R2s for clusters with size>5 with restriction')\n",
    "plt.xlabel('R2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "cluster_similarity={}\n",
    "for cluster in clusters:\n",
    "    chems=cluster['chems']\n",
    "    sims=[]\n",
    "    for combo in combinations(chems,2):\n",
    "        try:\n",
    "            sims.append(mrgn_jaccard(*combo))\n",
    "        except:\n",
    "            continue\n",
    "        cluster_similarity[cluster['cl_id']]=np.mean(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df['av_sim']=r2_df.index.to_series().map(cluster_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def make_metric(col,fpn):\n",
    "    def jaccard(sid1,sid2):\n",
    "        fp1_record=DB[col].find_one({'dsstox_sid':sid1})[fpn]\n",
    "        fp2_record=DB[col].find_one({'dsstox_sid':sid2})[fpn]\n",
    "        n1=fp1_record['n']\n",
    "        n2=fp2_record['n']\n",
    "        fp1=set(fp1_record['ds'])\n",
    "        fp2=set(fp2_record['ds'])\n",
    "        return len(fp1&fp2)/len(fp1|fp2)\n",
    "    return jaccard\n",
    "mrgn_jaccard=make_metric('chm_fp','mrgn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k,s grid search for LOAELS using mean aggregation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions=[]\n",
    "# for k in ks:\n",
    "#     for s in ss: \n",
    "#         for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "#                 prediction={category+'_p':wtavg(group,category,k,s) for category in categories}\n",
    "#                 prediction['dsstox_sid']=sid\n",
    "#                 prediction['k']=k\n",
    "#                 prediction['s']=s\n",
    "#                 predictions.append(prediction)\n",
    "# prediction_df=pd.DataFrame(predictions)\n",
    "# prediction_df=prediction_df.merge(loael_agg,left_on='dsstox_sid',right_index=True)\n",
    "# prediction_df.to_csv(DAT_DIR+'toxref_ks_gridsearch_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact_k_predictions=[]\n",
    "# for k in ks:\n",
    "#     for s in ss: \n",
    "#         for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "#                 prediction={category+'_p':exact_k_wtavg(group,category,k,s) for category in categories}\n",
    "#                 prediction['dsstox_sid']=sid\n",
    "#                 prediction['k']=k\n",
    "#                 prediction['s']=s\n",
    "#                 exact_k_predictions.append(prediction)\n",
    "# exact_k_df=pd.DataFrame(exact_k_predictions)\n",
    "# exact_k_df=exact_k_df.merge(loael_agg,left_on='dsstox_sid',right_index=True)\n",
    "# exact_k_df.to_csv(DAT_DIR+'toxref_exact_ks_gridsearch_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df=pd.read_csv(DAT_DIR+'toxref_ks_gridsearch_mrgn.csv')\n",
    "prediction_df=prediction_df.drop(columns=['Unnamed: 0'])\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_mean[loael_neighbors_mean.neighbor_sid=='DTXSID0024896']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverage calculations\n",
    "coverage_df=prediction_df[['k','s','dsstox_sid']+[category+'_p' for category in categories]]\n",
    "coverage_df=coverage_df[pd.notnull(coverage_df[[category+'_p' for category in categories]]).any(axis='columns')]\n",
    "coverage_df.pivot_table(index='k',columns='s',values='dsstox_sid',aggfunc=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dfs={category:prediction_df[['dsstox_sid',category,category+'_p','k','s']] for category in categories}\n",
    "for category,category_df in category_dfs.iteritems():\n",
    "    category_df.columns=['dsstox_sid','true','predicted','k','s']\n",
    "    category_df['endpoint_category']=category\n",
    "global_df=pd.concat(category_dfs.values())\n",
    "global_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(category_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df[global_df['dsstox_sid']=='DTXSID0020076']['endpoint_category'].value_counts()\n",
    "prediction_df[prediction_df['dsstox_sid']=='DTXSID7034672']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_mean[loael_neighbors_mean['target_sid']=='DTXSID7034672']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.to_csv(DAT_DIR+'global_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_grid_r2s=np.full([len(ks),len(ss)],np.nan)\n",
    "global_grid_ns=np.full([len(ks),len(ss)],np.nan)\n",
    "for (k,s),group in global_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        group=group[group.notnull().all(axis='columns')]\n",
    "        group=group[(group!=np.inf).all(axis=1)]\n",
    "        global_grid_ns[k_index,s_index]=len(group)\n",
    "        global_grid_r2s[k_index,s_index]=r2_score(group['true'],group['predicted'])\n",
    "global_grid_r2s=pd.DataFrame(global_grid_r2s,index=ks,columns=ss)\n",
    "global_grid_r2s.to_csv(DAT_DIR+'global_r2s.csv')\n",
    "global_grid_ns=pd.DataFrame(global_grid_ns,index=ks,columns=ss)\n",
    "global_grid_ns.to_csv(DAT_DIR+'global_ns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_grid_r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax=sns.heatmap(global_grid_r2s,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1,cbar_kws={'label':'R2'})\n",
    "ax.invert_yaxis()\n",
    "plt.title('global')\n",
    "plt.ylabel('k')\n",
    "plt.xlabel('s')\n",
    "plt.savefig(FIG_DIR+'global_r2s_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_r2s={category:np.full([len(ks),len(ss)],np.nan) for category in categories}\n",
    "grid_ns={category:np.full([len(ks),len(ss)],np.nan) for category in categories}\n",
    "for category in categories:\n",
    "    for (k,s),group in prediction_df.groupby(['k','s']):\n",
    "        df=plot_worthy(group[[category,category+'_p']])\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        grid_ns[category][k_index,s_index]=len(df)\n",
    "        if len(df)<=10:\n",
    "            continue\n",
    "        grid_r2s[category][k_index,s_index]=r2_score(df[category],df[category+'_p'])\n",
    "    grid_r2s[category]=pd.DataFrame(grid_r2s[category],index=ks,columns=ss)\n",
    "    grid_r2s[category].to_csv(DAT_DIR+category+'_r2s.csv')\n",
    "    grid_ns[category]=pd.DataFrame(grid_ns[category],index=ks,columns=ss)\n",
    "    grid_ns[category].to_csv(DAT_DIR+category+'_ns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category,r2_df in grid_r2s.iteritems():\n",
    "    ax=sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1,cbar_kws={'label':'R2'})\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(category)\n",
    "    plt.ylabel('k')\n",
    "    plt.xlabel('s')\n",
    "    plt.savefig(FIG_DIR+category+'_r2s_heatmap.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fontsize=20\n",
    "f=plt.figure(figsize=(30,15))\n",
    "f.suptitle('k,s grid search for up to k neighbors',fontsize=20)     \n",
    "ax = f.add_subplot(2,3,1)\n",
    "sns.heatmap(global_grid_r2s,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1, ax=ax,cbar_kws={'label':'R2'})\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('global',fontsize=fontsize)\n",
    "ax.set_ylabel('k',fontsize=fontsize)\n",
    "ax.set_xlabel('s',fontsize=fontsize)\n",
    "i=2\n",
    "for category in categories:\n",
    "    r2_df=grid_r2s[category]\n",
    "    ax = f.add_subplot(2,3,i)\n",
    "    sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1, ax=ax,cbar_kws={'label':'R2'})\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(category,fontsize=fontsize)\n",
    "    ax.set_ylabel('k',fontsize=fontsize)\n",
    "    ax.set_xlabel('s',fontsize=fontsize)\n",
    "    i+=1\n",
    "plt.savefig(FIG_DIR+'ksgrid_uptok_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(30,15))\n",
    "fig.suptitle('k,s grid search for up to k neighbors',fontsize=20)\n",
    "ax=fig.add_subplot(2,3,1,projection='3d')\n",
    "ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "ax.plot_surface(X,Y,global_grid_r2s)\n",
    "ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "ax.set_zlabel('R2')\n",
    "i=2\n",
    "for category in categories:\n",
    "    ax=fig.add_subplot(2,3,i,projection='3d')\n",
    "    i+=1\n",
    "    ax.text2D(.5,.95,category,transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    ax.plot_surface(X,Y,grid_r2s[category])\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "plt.savefig(FIG_DIR+'ksgrid_uptok')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_k_df=pd.read_csv(DAT_DIR+'toxref_exact_ks_gridsearch_mrgn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dfs=[exact_k_df[[category,category+'_p','k','s']] for category in categories]\n",
    "for category_df in category_dfs:\n",
    "    category_df.columns=['true','predicted','k','s']\n",
    "exactk_df=pd.concat(category_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_global_grid_r2s=np.full([len(ks),len(ss)],np.nan)\n",
    "exactk_global_grid_ns=np.full([len(ks),len(ss)],np.nan)\n",
    "for (k,s),group in exactk_df.groupby(['k','s']):\n",
    "        group=plot_worthy(group)\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))    \n",
    "        exactk_global_grid_ns[k_index,s_index]=len(group)\n",
    "        exactk_global_grid_r2s[k_index,s_index]=r2_score(group['true'],group['predicted'])\n",
    "exactk_global_grid_r2s=pd.DataFrame(exactk_global_grid_r2s,index=ks,columns=ss)\n",
    "exactk_global_grid_r2s.to_csv(DAT_DIR+'exactk_global_r2s.csv')\n",
    "exactk_global_grid_ns=pd.DataFrame(exactk_global_grid_ns,index=ks,columns=ss)\n",
    "exactk_global_grid_ns.to_csv(DAT_DIR+'exactk_global_ns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_grid_r2s={category:np.full([len(ks),len(ss)],np.nan) for category in categories}\n",
    "exactk_grid_ns={category:np.full([len(ks),len(ss)],np.nan) for category in categories}\n",
    "for category in categories:\n",
    "    for (k,s),group in exact_k_df.groupby(['k','s']):\n",
    "        df=group[[category,category+'_p']]\n",
    "        df=plot_worthy(df)\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))    \n",
    "        exactk_grid_ns[category][k_index,s_index]=len(df)\n",
    "        if len(df)<=10:\n",
    "            continue\n",
    "        exactk_grid_r2s[category][k_index,s_index]=r2_score(df[category],df[category+'_p'])\n",
    "    exactk_grid_r2s[category]=pd.DataFrame(exactk_grid_r2s[category],index=ks,columns=ss)\n",
    "    exactk_grid_r2s[category].to_csv(DAT_DIR+'exactk_' + category + '_r2s.csv')\n",
    "    exactk_grid_ns[category]=pd.DataFrame(exactk_grid_ns[category],index=ks,columns=ss) \n",
    "    exactk_grid_ns[category].to_csv(DAT_DIR+'exactk_' + category + '_ns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.heatmap(exactk_global_grid_r2s,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1,cbar_kws={'label':'R2'})\n",
    "ax.invert_yaxis()\n",
    "plt.title('global')\n",
    "plt.xlabel('s')\n",
    "plt.ylabel('k')\n",
    "plt.savefig(FIG_DIR+'exactk_global_r2s_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category,r2_df in exactk_grid_r2s.iteritems():\n",
    "    ax=sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1,cbar_kws={'label':'R2'})\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(category)\n",
    "    plt.ylabel('k')\n",
    "    plt.xlabel('s')\n",
    "    plt.savefig(FIG_DIR+'exactk_'+category+'_r2s_heatmap.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fontsize=20\n",
    "f=plt.figure(figsize=(30,15))\n",
    "f.suptitle('k,s grid search for exactly k neighbors',fontsize=20)     \n",
    "ax = f.add_subplot(2,3,1)\n",
    "sns.heatmap(exactk_global_grid_r2s,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1, ax=ax,cbar_kws={'label':'R2'})\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('global',fontsize=fontsize)\n",
    "ax.set_ylabel('k',fontsize=fontsize)\n",
    "ax.set_xlabel('s',fontsize=fontsize)\n",
    "i=2\n",
    "for category in categories:\n",
    "    r2_df=exactk_grid_r2s[category]\n",
    "    ax = f.add_subplot(2,3,i)\n",
    "    sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1, ax=ax,cbar_kws={'label':'R2'})\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(category,fontsize=fontsize)\n",
    "    ax.set_ylabel('k',fontsize=fontsize)\n",
    "    ax.set_xlabel('s',fontsize=fontsize)\n",
    "    i+=1\n",
    "plt.savefig(FIG_DIR+'exactk_ksgrid_uptok_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(30,15))\n",
    "fig.suptitle('k,s grid search for exactly k neighbors',fontsize=20)\n",
    "ax=fig.add_subplot(2,3,1,projection='3d')\n",
    "ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "ax.plot_surface(X,Y,exactk_global_grid_r2s[exactk_global_grid_ns>=30])\n",
    "ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "ax.set_zlabel('R2')\n",
    "i=2\n",
    "for category in categories:\n",
    "    ax=fig.add_subplot(2,3,i,projection='3d')\n",
    "    i+=1\n",
    "    ax.text2D(.5,.95,category,transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    ax.plot_surface(X,Y,exactk_grid_r2s[category][exactk_grid_ns[category]>=30])\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "plt.savefig(FIG_DIR+'ksgrid_exactk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_global_grid_ns=exactk_global_grid_ns.astype(int)\n",
    "print('Global')\n",
    "exactk_global_grid_ns\n",
    "for category in categories:\n",
    "    print(category)\n",
    "    exactk_grid_ns[category]=exactk_grid_ns[category].astype(int)\n",
    "    exactk_grid_ns[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(9,6))\n",
    "plt.subplot(2,3,1)\n",
    "ax=Axes3D(fig)\n",
    "ax.text2D(.5,.95,'n for exactly k neighbors for global',transform=ax.transAxes)\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "ax.plot_surface(X,Y,exactk_global_grid_ns)\n",
    "ax.set_ylabel('Maximum number of neighbors (k)')\n",
    "ax.set_xlabel('Similarity threshold (s)')\n",
    "ax.set_zlabel('n')\n",
    "i=2\n",
    "for category in categories:\n",
    "    fig=plt.figure(figsize=(9,6))\n",
    "    plt.subplot(2,3,i)\n",
    "    i+=1\n",
    "    ax=Axes3D(fig)\n",
    "    ax.text2D(.5,.95,'n for exactly k neighbors for ' + category,transform=ax.transAxes)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    ax.plot_surface(X,Y,exactk_grid_ns[category])\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)')\n",
    "    ax.set_xlabel('Similarity threshold (s)')\n",
    "    ax.set_zlabel('n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k,s grid search over clusters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dfs={category:cluster_prediction_df[[category,category+'_p','k','s','cluster']] for category in categories}\n",
    "for category,category_df in category_dfs.iteritems():\n",
    "    category_df.columns=['true','predicted','k','s','cluster']\n",
    "    category_df['category']=category\n",
    "cluster_df=pd.concat(category_dfs.values())\n",
    "cluster_df=cluster_df[cluster_df.notnull().all(axis='columns')]\n",
    "cluster_df=cluster_df[(cluster_df!=np.inf).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dfs={category:exactk_cluster_prediction_df[[category,category+'_p','k','s','cluster']] for category in categories}\n",
    "for category,category_df in category_dfs.iteritems():\n",
    "    category_df.columns=['true','predicted','k','s','cluster']\n",
    "    category_df['category']=category\n",
    "exactk_cluster_df=pd.concat(category_dfs.values())\n",
    "exactk_cluster_df=exactk_cluster_df[exactk_cluster_df.notnull().all(axis='columns')]\n",
    "exactk_cluster_df=exactk_cluster_df[(exactk_cluster_df!=np.inf).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_matrix(cdf):\n",
    "    cdf=cdf.groupby(['k','s']).apply(lambda x: r2_score(x['true'],x['predicted']))\n",
    "    if cdf.empty:\n",
    "        return np.nan\n",
    "    cdf=cdf.unstack().reindex(index=ks,columns=ss)\n",
    "    return cdf\n",
    "def n_matrix(cdf):\n",
    "    cdf=cdf.groupby(['k','s']).apply(lambda x: len(x))\n",
    "    if cdf.empty:\n",
    "        return np.nan\n",
    "    cdf=cdf.unstack().reindex(index=ks,columns=ss)\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cluster_grid_r2s={}\n",
    "global_cluster_grid_ns={}\n",
    "for clid, cdf in exactk_cluster_df.groupby(['cluster']):\n",
    "    clid=int(clid)\n",
    "    global_cluster_grid_r2s[clid]=r2_matrix(cdf)\n",
    "    global_cluster_grid_ns[clid]=n_matrix(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_grid_r2s={}\n",
    "cluster_grid_ns={}\n",
    "for clid, cdf in cluster_df.groupby(['cluster']):\n",
    "    clid=int(clid)\n",
    "    cluster_grid_r2s[clid]={endpoint_category: r2_matrix(cdf[cdf.category==endpoint_category]) for endpoint_category in categories}\n",
    "    cluster_grid_ns[clid]={endpoint_category: r2_matrix(cdf[cdf.category==endpoint_category]) for endpoint_category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_grid_r2s={}\n",
    "exactk_cluster_grid_ns={}\n",
    "for clid, cdf in exactk_cluster_df.groupby(['cluster']):\n",
    "    clid=int(clid)\n",
    "    exactk_cluster_grid_r2s[clid]={endpoint_category: r2_matrix(cdf[cdf.category==endpoint_category]) for endpoint_category in categories}\n",
    "    exactk_cluster_grid_ns[clid]={endpoint_category: r2_matrix(cdf[cdf.category==endpoint_category]) for endpoint_category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_grid_r2s[0]['systemic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_grid_r2s={}\n",
    "cluster_grid_ns={}\n",
    "for cluster in clusters:\n",
    "    clid=int(cluster['cl_id'])\n",
    "    cluster_grid_r2s[clid]={}\n",
    "    for endpoint_category in categories:\n",
    "        chems=cluster['chems']\n",
    "        cluster_grid_r2s[clid][endpoint_category]=np.empty([len(ks),len(ss)])\n",
    "        cluster_grid_ns[clid]={}\n",
    "        cluster_grid_ns[clid][endpoint_category]=np.empty([len(ks),len(ss)])\n",
    "        for (k,s),group in cluster_prediction_df.groupby(['k','s']):\n",
    "            k_index=ks.index(k)\n",
    "            s_index=ss.index(round(s,2))\n",
    "            df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems))\\\n",
    "                                     & (cluster_prediction_df['s']==s) & (cluster_prediction_df['k']==k)]\n",
    "            df=df[[endpoint_category,endpoint_category+'_p']]\n",
    "            df=plot_worthy(df)\n",
    "            if df.empty:\n",
    "                cluster_grid_r2s[clid][endpoint_category][k_index,s_index]=np.nan\n",
    "                cluster_grid_ns[clid][endpoint_category][k_index,s_index]=0   \n",
    "                continue\n",
    "            cluster_grid_r2s[clid][endpoint_category][k_index,s_index]=r2_score(df[endpoint_category],df[endpoint_category+'_p'])\n",
    "            cluster_grid_ns[clid][endpoint_category][k_index,s_index]=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open(DAT_DIR+'cluster_gridsearch.pkl','w') as f:\n",
    "#     pkl.dump(cluster_grid_r2s,f)\n",
    "# with open(DAT_DIR+'cluster_gridsearch_ns.pkl','w') as f:\n",
    "#     pkl.dump(cluster_grid_ns,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(DAT_DIR+'cluster_gridsearch.pkl') as f:\n",
    "    cluster_grid_r2s=pkl.load(f)\n",
    "with open(DAT_DIR+'cluster_gridsearch_ns.pkl') as f:\n",
    "    cluster_grid_ns=pkl.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cluster_grid_r2s[5]['systemic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_global_cluster_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exactk_cluster_grid_r2s={}\n",
    "# exactk_cluster_grid_ns={}\n",
    "# for cluster in clusters:\n",
    "#     clid=int(cluster['cl_id'])\n",
    "#     exactk_cluster_grid_r2s[clid]={}\n",
    "#     for endpoint_category in categories:\n",
    "#         chems=cluster['chems']\n",
    "#         exactk_cluster_grid_r2s[clid][endpoint_category]=np.empty([len(ks),len(ss)])\n",
    "#         exactk_cluster_grid_ns[clid]={}\n",
    "\n",
    "#         exactk_cluster_grid_ns[clid][endpoint_category]=np.empty([len(ks),len(ss)])\n",
    "#         for (k,s),group in exactk_cluster_prediction_df.groupby(['k','s']):\n",
    "#             k_index=ks.index(k)\n",
    "#             s_index=ss.index(round(s,2))\n",
    "#             df=exactk_cluster_prediction_df[(exactk_cluster_prediction_df['dsstox_sid'].isin(chems))\\\n",
    "#                                      & (exactk_cluster_prediction_df['s']==s) & (exactk_cluster_prediction_df['k']==k)]\n",
    "#             df=df[[endpoint_category,endpoint_category+'_p']]\n",
    "#             df=plot_worthy(df)\n",
    "#             if df.empty:\n",
    "#                 exactk_cluster_grid_r2s[clid][endpoint_category][k_index,s_index]=np.nan\n",
    "#                 exactk_cluster_grid_ns[clid][endpoint_category][k_index,s_index]=0   \n",
    "#                 continue\n",
    "#             exactk_cluster_grid_r2s[clid][endpoint_category][k_index,s_index]=r2_score(df[endpoint_category],df[endpoint_category+'_p'])\n",
    "#             exactk_cluster_grid_ns[clid][endpoint_category][k_index,s_index]=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open(DAT_DIR+'exactk_cluster_gridsearch.pkl','w') as f:\n",
    "#     pkl.dump(exactk_cluster_grid_r2s,f)\n",
    "# with open(DAT_DIR+'exactk_cluster_gridsearch_ns.pkl','w') as f:\n",
    "#     pkl.dump(exactk_cluster_grid_ns,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(DAT_DIR+'exactk_cluster_gridsearch.pkl') as f:\n",
    "    exactk_cluster_grid_r2s=pkl.load(f)\n",
    "with open(DAT_DIR+'exactk_cluster_gridsearch_ns.pkl') as f:\n",
    "    exactk_cluster_grid_ns=pkl.load(f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imran asked for heatmaps for these specific clusters.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran_clusters=[1,5,7,25,31,55,67]\n",
    "for clid in imran_clusters:\n",
    "    for endpoint_category in cluster_grid_r2s[clid].keys():\n",
    "        r2_df=cluster_grid_r2s[clid][endpoint_category]\n",
    "        ax=sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1,cbar_kws={'label':'R2'})\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Cluster ' + str(clid) + ' ' + endpoint_category)\n",
    "        plt.ylabel('k')\n",
    "        plt.xlabel('s')\n",
    "        plt.savefig(FIG_DIR+'imran_clusters/'+'uptok_cluster_'+str(clid)+'_'+endpoint_category+'_heatmap')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran_clusters=[1,5,7,25,31,55,67]\n",
    "for clid in imran_clusters:\n",
    "    for endpoint_category in cluster_grid_r2s[clid].keys():\n",
    "        r2_df=exactk_cluster_grid_r2s[clid][endpoint_category]\n",
    "        ax=sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1,cbar_kws={'label':'R2'})\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Cluster ' + str(clid) + ' ' + endpoint_category)\n",
    "        plt.ylabel('k')\n",
    "        plt.xlabel('s')\n",
    "        plt.savefig(FIG_DIR+'imran_clusters/'+'exactk_cluster_'+str(clid)+'_'+endpoint_category+'_heatmap')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fontsize=20\n",
    "f=plt.figure(figsize=(30,15))\n",
    "f.suptitle('k,s grid search for exactly k neighbors',fontsize=20)     \n",
    "ax = f.add_subplot(2,3,1)\n",
    "sns.heatmap(exactk_global_grid_r2s,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1, ax=ax,cbar_kws={'label':'R2'})\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('global',fontsize=fontsize)\n",
    "ax.set_ylabel('k',fontsize=fontsize)\n",
    "ax.set_xlabel('s',fontsize=fontsize)\n",
    "i=2\n",
    "for category in categories:\n",
    "    r2_df=exactk_grid_r2s[category]\n",
    "    ax = f.add_subplot(2,3,i)\n",
    "    sns.heatmap(r2_df,cmap=plt.cm.coolwarm,vmin=-.5,vmax=.5,linewidth=1, ax=ax,cbar_kws={'label':'R2'})\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(category,fontsize=fontsize)\n",
    "    ax.set_ylabel('k',fontsize=fontsize)\n",
    "    ax.set_xlabel('s',fontsize=fontsize)\n",
    "    i+=1\n",
    "plt.savefig(FIG_DIR+'exactk_ksgrid_uptok_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EPA Categories Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "op_dict={\n",
    "    'GreaterThan': op.gt,\n",
    "    'GreaterThanOrEqualTo': op.ge,\n",
    "    'LessThan': op.lt,\n",
    "    'LessThanOrEqualTo': op.le\n",
    "}\n",
    "prop_dict={\n",
    "    'log Kow':'logp',\n",
    "    'Molecular Weight':'mol_weight',\n",
    "    'Molecular weight':'mol_weight',\n",
    "    'Water Solubility': 'ws'\n",
    "}\n",
    "def convert_ppb(x): #OPERA results stored as mol/L\n",
    "    ws=x['ws']\n",
    "    mol_weight=x['mol_weight']\n",
    "    return ws*mol_weight*10**6\n",
    "import dill\n",
    "with open(DAT_DIR+'../category_tests.dill') as f:\n",
    "    category_tests=dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_smiles=dsstox.find({'dsstox_sid':{'$in':loael_sids}},{'_id':0,'dsstox_sid':1,'smiles':1})\n",
    "smiles_dict={record['dsstox_sid']:record['smiles'] for record in loael_smiles}\n",
    "loael_logp=physprop.find({'dsstox_sid':{'$in':loael_sids}},{'_id':0,'dsstox_sid':1,'predicted_props.OPERA_LogP':1})\n",
    "logp_dict={record['dsstox_sid']:record.get('predicted_props',{})['OPERA_LogP'][0] for record in loael_logp \\\n",
    "           if 'OPERA_LogP' in record.get('predicted_props',{}) and record.get('dsstox_sid',None)}\n",
    "loael_ws=physprop.find({'dsstox_sid':{'$in':loael_sids}},{'_id':0,'dsstox_sid':1,'predicted_props.OPERA_WS':1})\n",
    "ws_dict={record['dsstox_sid']:record.get('predicted_props',{})['OPERA_WS'][0] for record in loael_ws \\\n",
    "           if 'OPERA_WS' in record.get('predicted_props',{}) and record.get('dsstox_sid',None)}\n",
    "loael_weight=dsstox.find({'dsstox_sid':{'$in':loael_sids}})\n",
    "weight_dict={record['dsstox_sid']:record['mol_weight'] for record in loael_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "sids=set(logp_dict.keys())&set(ws_dict.keys())&set(weight_dict.keys())\n",
    "records=[]\n",
    "for sid in sids:\n",
    "    records.append({'dsstox_sid':sid,'smiles':smiles_dict[sid],'logp':logp_dict[sid],'ws':ws_dict[sid],'mol_weight':weight_dict[sid],'mol':Chem.MolFromSmiles(smiles_dict[sid])})\n",
    "records=[record for record in records if record['mol']]\n",
    "\n",
    "import math\n",
    "for record in records:\n",
    "    if not record['mol']:\n",
    "        continue\n",
    "    epa_categories=sorted([category for category,test in category_tests.iteritems() if test(record)])\n",
    "    if 'Neutral Organics' in epa_categories and len(epa_categories)>1:\n",
    "        epa_categories.remove('Neutral Organics')\n",
    "    record['categories']=tuple(epa_categories)\n",
    "\n",
    "from collections import Counter\n",
    "count=Counter(record['categories'] for record in records)\n",
    "count\n",
    "\n",
    "from collections import defaultdict\n",
    "search_spaces=defaultdict(list)\n",
    "for record in records:\n",
    "    search_spaces[record['categories']].append(record['dsstox_sid'])\n",
    "search_spaces={cat:l for cat,l in search_spaces.iteritems() if len(l)>1}\n",
    "import pickle\n",
    "with open(DAT_DIR+'search_spaces.pkl','w') as f:\n",
    "    pickle.dump(search_spaces,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors_l=[]\n",
    "for record in records:\n",
    "    sid=record['dsstox_sid']\n",
    "    search_space=search_spaces[record['categories']][:]\n",
    "    if len(search_space)==1:\n",
    "        continue\n",
    "    search_space.remove(sid)\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=search_space,DB=DB)\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        category_neighbors_l=category_neighbors_l+sid_neighbors\n",
    "        \n",
    "category_neighbors=pd.DataFrame(category_neighbors_l)\n",
    "category_neighbors=category_neighbors[category_neighbors['target_sid']!=category_neighbors['neighbor_sid']]\n",
    "category_neighbors=category_neighbors.merge(loael_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "category_neighbors=category_neighbors.sort_values('jaccard',ascending=False)\n",
    "category_neighbors.to_csv(DAT_DIR+'category_neighbors_mrgn.csv',index=False)\n",
    "category_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in category_neighbors.groupby('target_sid'):\n",
    "    predictions[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}\n",
    "\n",
    "category_predictions=pd.DataFrame(predictions.values(),index=predictions.keys())\n",
    "category_predictions=category_predictions.merge(loael_agg_mean,right_index=True,left_index=True)\n",
    "category_predictions.to_csv(DAT_DIR+'category_predictions_mrgn.csv')\n",
    "category_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors=pd.read_csv(DAT_DIR+'category_neighbors_mrgn.csv')\n",
    "category_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions=pd.read_csv(DAT_DIR+'category_predictions_mrgn.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Category Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=category_predictions[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "search_spaces=pickle.load(open(DAT_DIR+'search_spaces.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_r2s=[]\n",
    "for category,search_space in search_spaces.iteritems():\n",
    "    df=category_predictions.loc[search_space][['systemic','systemic_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    category_r2s.append({'R2':r2_score(df['systemic'],df['systemic_p']),'size':len(df),'category':category})\n",
    "    if len(df)>5:\n",
    "        plt.scatter(df['systemic'],df['systemic_p'])\n",
    "        plt.title(str(category) + ' systemic LOAEL predictions')\n",
    "        plt.xlabel('True')\n",
    "        plt.ylabel('Predicted')\n",
    "        range_setter='systemic'\n",
    "        if (max(df['systemic_p'])-min(df['systemic_p']))>(max(df['systemic'])-min(df['systemic'])):\n",
    "            range_setter=range_setter+'_p'\n",
    "        plt.xlim(min(df[range_setter])-.01,max(df[range_setter])+.01)\n",
    "        plt.ylim(min(df[range_setter])-.01,max(df[range_setter])+.01)\n",
    "        plt.annotate('R2='+str(round(r2_score(df['systemic'],df['systemic_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "        plt.annotate('n='+str(len(df)),xy=(.03,.88),xycoords='axes fraction')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_r2_df=pd.DataFrame(category_r2s)\n",
    "epa_r2_gt_5=epa_r2_df[epa_r2_df['size']>=5]\n",
    "plt.hist(epa_r2_gt_5['R2'])\n",
    "plt.title('Systemic R2s for clusters with size>5 within category')\n",
    "plt.xlabel('R2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_r2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cluster/Category Comparison</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_category_dict={chem:epa_category for epa_category,list_of_chems in search_spaces.iteritems() for chem in list_of_chems}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sids=[chem for cluster in clusters for chem in cluster['chems']]\n",
    "cluster_sids=set(loael_agg[loael_agg.index.isin(cluster_sids)].index.values)\n",
    "cluster_map={sid:int(cluster['cl_id']) for cluster in clusters for sid in cluster['chems'] if sid in cluster_sids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_category_sids=set(epa_category_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_sids)\n",
    "len(epa_category_sids)\n",
    "len(cluster_sids&epa_category_sids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat=pd.DataFrame(np.zeros(shape=(len(search_spaces.keys()),len(clusters))),\n",
    "                    index=search_spaces.keys(),columns=[int(cluster['cl_id']) for cluster in clusters])\n",
    "for sid in cluster_sids&epa_category_sids:\n",
    "    adj_mat.loc[[epa_category_dict[sid]],cluster_map[sid]]+=1\n",
    "adj_mat=adj_mat.loc[:,adj_mat.sum(axis=0)>0]\n",
    "adj_mat=adj_mat.drop(('Anilines (Acute toxicity)', 'Phenols (Acute toxicity)'),) #None in clusters\n",
    "with pd.option_context('display.max_columns',None):\n",
    "    adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals=pd.DataFrame(adj_mat.sum(1),columns=['total'])\n",
    "adj_mat_perc=adj_mat.div(adj_mat.sum(axis='columns'),axis='rows').applymap(\"{:.2%}\".format)\n",
    "adj_mat_perc['total']=totals\n",
    "adj_mat_perc['R2']=adj_mat_perc.index\n",
    "adj_mat_perc['R2']=adj_mat_perc['R2'].astype('string')\n",
    "adj_mat_perc['R2']=adj_mat_perc['R2'].map({str(row['category']):row['R2'] for i,row in epa_r2_df.iterrows()})\n",
    "with pd.option_context('display.max_columns',None):\n",
    "    adj_mat_perc\n",
    "adj_mat_perc.to_csv(DAT_DIR+'cluster_category_adjacency_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals=pd.DataFrame(adj_mat.sum(0),columns=['total'])\n",
    "adj_mat_ratio=totals.T.append(adj_mat.div(adj_mat.sum(axis='rows'),axis='columns'))\n",
    "categorized_clusters=adj_mat_ratio.loc[:,((adj_mat_ratio.loc[[()]]<.4).squeeze()) & (adj_mat_ratio.loc['total']>10)]\n",
    "categorized_cluster_ids=categorized_clusters.columns.values\n",
    "r2_df.loc[[str(cl_id) for cl_id in categorized_cluster_ids]]\n",
    "r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "adj_mat_heat=adj_mat.div(adj_mat.sum(axis='columns'),axis='rows')\n",
    "fig,ax=plt.subplots(figsize=(240,72))\n",
    "with plt.rc_context({'xtick.labelsize':24,'ytick.labelsize':24}):\n",
    "    sns.heatmap(adj_mat_heat,yticklabels=True)\n",
    "plt.savefig(FIG_DIR+'cluster_category_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do phthalates categorize?\n",
    "phthalate_sids=[record['dsstox_sid'] for record in dsstox.find({'$and':[{'dsstox_sid':{'$in':list(epa_category_sids)}},{'name':{'$regex':'phthalate'}}]})]\n",
    "phthalate_sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[epa_category_dict[sid] for sid in phthalate_sids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do perfluoro compounds categorize?\n",
    "perfluoro_sids=[record['dsstox_sid'] for record in dsstox.find({'$and':[{'dsstox_sid':{'$in':list(epa_category_sids)}},{'name':{'$regex':'perfluoro'}}]})]\n",
    "perfluoro_sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw some clusters\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "mols=[Chem.MolFromSmiles(record['smiles']) for record in dsstox.find({'dsstox_sid':{'$in':cluster_dict['80']}})]\n",
    "for mol in mols:\n",
    "    Draw.MolToMPL(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
