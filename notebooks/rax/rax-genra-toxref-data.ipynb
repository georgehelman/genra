{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import sys\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import matplotlib as plt\n",
    "\n",
    "TOP = '/'.join(os.getcwd().split('/')[:-2])+'/'\n",
    "LIB = TOP+'lib'\n",
    "if not LIB in sys.path: \n",
    "    sys.path.insert(0,LIB)\n",
    "\n",
    "DAT_DIR = TOP + 'data/toxref/'\n",
    "FIG_DIR = TOP + 'figs/toxref/'\n",
    "\n",
    "from rax.genrapred import *\n",
    "\n",
    "mongocon=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_dev_v4\")\n",
    "DB=mongocon['genra_dev_v4']\n",
    "dsstox=DB['compound']\n",
    "toxref=DB['toxrefdb2']\n",
    "physprop=DB['physprop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_k_wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if len(df)<k:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EDA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(toxref.count()) + ' total substances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxref.find_one({'pods.effect_profile_id':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pod_record(document):\n",
    "    pods=document['pods']\n",
    "    for pod in pods:\n",
    "        pod['dsstox_sid']=document['dsstox_sid']\n",
    "    return pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df=pd.DataFrame([pod for document in toxref.find() for pod in pod_record(document)])\n",
    "#pods_df=pods_df[pods_df['effect_profile_id']==2] #Turns out they all equal 2\n",
    "with pd.option_context('display.max_columns',None):\n",
    "    pods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df['effect_profile_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to convert to log molar\n",
    "sids=list(pods_df['dsstox_sid'].unique())\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':sids}})}\n",
    "pods_df['mol_weight']=pods_df['dsstox_sid'].map(weights)\n",
    "pods_df['pod_value_LM']=-np.log10(pods_df['pod_value']/pods_df['mol_weight']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_df=pods_df[pods_df['pod_type']=='loael']\n",
    "loael_df.to_csv(DAT_DIR+'loael.csv',encoding='utf-8')\n",
    "lel_df=pods_df[pods_df['pod_type']=='lel']\n",
    "lel_df.to_csv(DAT_DIR+'lel.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df.pivot_table(index='pod_type',values='dsstox_sid',aggfunc=lambda x: len(x.unique())) #Unique sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df['pod_unit'].value_counts()\n",
    "pods_df=pods_df[pods_df['pod_unit']=='mg/kg/day'] #Don't feel like dealing with this\n",
    "print(str(len(pods_df))+' have units mg/kg/day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pods_df['dsstox_sid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df['qualifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pods_df.boxplot('pod_value',by='pod_type',figsize=(8,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_df.boxplot('pod_value_LM',by='pod_type',figsize=(8,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(pods_df,index='endpoint_category',columns='pod_type',values='dsstox_sid',aggfunc=lambda x: len(x.unique()),fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(pods_df,index='endpoint_type',columns='pod_type',values='dsstox_sid',aggfunc=lambda x: len(x.unique()),fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_df.pivot_table(index='endpoint_type',columns='endpoint_category',values='dsstox_sid',aggfunc=lambda x: len(x.unique()),fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assay_counts=pods_df.groupby(endpoint_cols).size().reset_index().rename(columns={0:'count'}).sort_values('count',ascending=False)\n",
    "# assay_counts.head()\n",
    "# len(assay_counts)\n",
    "# len(assay_counts[assay_counts['count']>30])\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    pd.DataFrame(pd.pivot_table(pods_df,index=['pod_type','endpoint_category','endpoint_type','endpoint_target'],values='dsstox_sid',aggfunc=lambda x: len(x.unique()),fill_value=0))\\\n",
    "    .rename(columns={'pod_value':'pod_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstudies=loael_df.pivot_table(index='dsstox_sid',values='pod_value',aggfunc=len)\n",
    "plt.hist(nstudies.values,bins=30)\n",
    "plt.title('Number of studies per chemical')\n",
    "plt.xlabel('Number of Studies')\n",
    "plt.ylabel('Count of Chemicals')\n",
    "plt.savefig(FIG_DIR+'nhist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg=loael_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='min')\n",
    "loael_agg.to_csv(DAT_DIR+'loaelagg.csv',encoding='utf-8')\n",
    "lel_agg=lel_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='min')\n",
    "lel_agg.to_csv(DAT_DIR+'lelagg.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(loael_agg))+' total substances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_sids=list(set(loael_agg.index.values))\n",
    "lel_sids=list(set(lel_agg.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loael_agg.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_l=[]\n",
    "for sid in loael_sids:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=loael_sids,DB=DB,col='chemotypes',fpn='chemotypes')\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        loael_neighbors_l=loael_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lel_neighbors_l=[]\n",
    "for sid in lel_sids:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=loael_sids,DB=DB,col='chemotypes',fpn='chemotypes')\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        lel_neighbors_l=lel_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors=pd.read_csv(DAT_DIR+'loael_predictions.csv')\n",
    "len(loael_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors=pd.DataFrame(loael_neighbors_l)\n",
    "loael_neighbors=loael_neighbors[loael_neighbors['target_sid']!=loael_neighbors['neighbor_sid']]\n",
    "loael_neighbors=loael_neighbors.merge(loael_agg,left_on='neighbor_sid',right_index=True)\n",
    "loael_neighbors=loael_neighbors.sort_values('jaccard',ascending=False)\n",
    "loael_neighbors.to_csv(DAT_DIR+'loael_neighbors.csv')\n",
    "loael_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lel_neighbors=pd.DataFrame(lel_neighbors_l)\n",
    "lel_neighbors=lel_neighbors[lel_neighbors['target_sid']!=lel_neighbors['neighbor_sid']]\n",
    "lel_neighbors=lel_neighbors.merge(lel_agg,left_on='neighbor_sid',right_index=True)\n",
    "lel_neighbors=lel_neighbors.sort_values('jaccard',ascending=False)\n",
    "lel_neighbors.to_csv(DAT_DIR+'lel_neighbors.csv')\n",
    "lel_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=list(loael_agg.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BMDs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmd_record(document):\n",
    "    bmds=document['bmds']\n",
    "    for bmd in bmds:\n",
    "        bmd['dsstox_sid']=document['dsstox_sid']\n",
    "    return bmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_df=pd.DataFrame([bmd for document in toxref.find({'bmds':{'$exists':True}}) for bmd in bmd_record(document)])\n",
    "with pd.option_context('display.max_columns',None):\n",
    "    bmd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids=list(bmd_df['dsstox_sid'].unique())\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':sids}})}\n",
    "bmd_df['mol_weight']=bmd_df['dsstox_sid'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_df=bmd_df.sort_values('AIC')\n",
    "#bmd_df=bmd_df.reset_index()\n",
    "with pd.option_context('display.max_columns',None):\n",
    "    bmd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_agg=bmd_df.pivot_table(index=['dsstox_sid','bmr_type'],columns='endpoint_category',values='BMD_LM',aggfunc='first') #May want to average in the case of multiple models with same AIC\n",
    "bmd_agg.to_csv(DAT_DIR+'bmdagg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_sids=list(bmd_agg.index.unique(level='dsstox_sid'))\n",
    "bmd_neighbors_l=[]\n",
    "for sid in bmd_sids:\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=bmd_sids,DB=DB,col='chemotypes',fpn='chemotypes')\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "            neighbor['neighbor_name']=neighbor.pop('name',None)\n",
    "        bmd_neighbors_l=bmd_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_neighbors=pd.DataFrame(bmd_neighbors_l)\n",
    "bmd_neighbors=bmd_neighbors[bmd_neighbors['target_sid']!=bmd_neighbors['neighbor_sid']]\n",
    "bmd_neighbors=bmd_neighbors.merge(bmd_agg.reset_index(1),left_on='neighbor_sid',right_index=True)\n",
    "bmd_neighbors=bmd_neighbors.sort_values('jaccard',ascending=False)\n",
    "bmd_neighbors.to_csv(DAT_DIR+'bmd_neighbors.csv')\n",
    "bmd_neighbors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mean Aggregation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean=loael_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='mean')\n",
    "loael_agg_sd=loael_df.pivot_table(index='dsstox_sid',columns='endpoint_category',values='pod_value_LM',aggfunc='std')\n",
    "loael_agg_sd=loael_agg_sd.loc[loael_agg_mean.index]\n",
    "loael_agg_mean.to_csv(DAT_DIR+'loael_agg_mean.csv')\n",
    "loael_agg_sd.to_csv(DAT_DIR+'loael_agg_sd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_mean=pd.DataFrame(loael_neighbors_l)\n",
    "loael_neighbors_mean=loael_neighbors_mean[loael_neighbors_mean['target_sid']!=loael_neighbors_mean['neighbor_sid']]\n",
    "loael_neighbors_mean=loael_neighbors_mean.merge(loael_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "loael_neighbors_mean=loael_neighbors_mean.sort_values('jaccard',ascending=False)\n",
    "loael_neighbors_mean.to_csv(DAT_DIR+'loael_neighbors_mean.csv')\n",
    "loael_neighbors_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_sd=pd.DataFrame(loael_neighbors_l)\n",
    "loael_neighbors_sd=loael_neighbors_sd[loael_neighbors_sd['target_sid']!=loael_neighbors_sd['neighbor_sid']]\n",
    "loael_neighbors_sd=loael_neighbors_sd.merge(loael_agg_sd,left_on='neighbor_sid',right_index=True)\n",
    "loael_neighbors_sd=loael_neighbors_sd.loc[loael_neighbors_mean.index]\n",
    "loael_neighbors_sd.to_csv(DAT_DIR+'loael_neighbors_sd.csv')\n",
    "loael_neighbors_sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtvar(df,name,k):\n",
    "    df=df[(df[name].notnull()) & (df[name]!=np.inf)].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return sum([weights[i]**2*values[i] for i in range(len(values))])/sum(weights)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mean={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "    predictions_mean[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sd={}\n",
    "k=10\n",
    "for sid,group in loael_neighbors_sd.groupby('target_sid'):\n",
    "    predictions_sd[sid]={category:wtvar(group,category,k) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_predictions_mean=pd.DataFrame(predictions_mean.values(),index=predictions_mean.keys())\n",
    "loael_predictions_mean=loael_predictions_mean.merge(loael_agg_mean,right_index=True,left_index=True)\n",
    "len(loael_predictions_mean)\n",
    "loael_predictions_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Mean Aggregation Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=loael_predictions_mean[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cluster Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_v3\")\n",
    "DB2 = con['genra_v3']\n",
    "clusters_collection=DB2['clusters1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=list(clusters_collection.find({},{'_id':0,'chems':1,'cl_id':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_list=[chem for cluster in [cluster['chems'] for cluster in clusters] for chem in cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_to_sid={record['dsstox_cid']:record['dsstox_sid'] for record in dsstox.find({'dsstox_cid':{'$in':cid_list}})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    cluster['chems']=[cid_to_sid[cid] for cid in cluster['chems'] if cid in cid_to_sid.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(DAT_DIR+'clusters.pkl','w') as f:\n",
    "    pkl.dump(clusters,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k,s grid search for LOAELS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "ks=range(1,20)\n",
    "ss=[round(s/20,2) for s in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for k in ks:\n",
    "    for s in ss: \n",
    "        for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "                prediction={category+'_p':wtavg(group,category,k,s) for category in categories}\n",
    "                prediction['dsstox_sid']=sid\n",
    "                prediction['k']=k\n",
    "                prediction['s']=s\n",
    "                predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_df=pd.DataFrame(predictions)\n",
    "# prediction_df=prediction_df.merge(loael_agg,left_on='dsstox_sid',right_index=True)\n",
    "# prediction_df.to_csv(DAT_DIR+'toxref_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact_k_predictions=[]\n",
    "# for k in ks:\n",
    "#     for s in ss: \n",
    "#         for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "#                 prediction={category+'_p':exact_k_wtavg(group,category,k,s) for category in categories}\n",
    "#                 prediction['dsstox_sid']=sid\n",
    "#                 prediction['k']=k\n",
    "#                 prediction['s']=s\n",
    "#                 exact_k_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact_k_df=pd.DataFrame(exact_k_predictions)\n",
    "# exact_k_df=exact_k_df.merge(loael_agg,left_on='dsstox_sid',right_index=True)\n",
    "# exact_k_df.to_csv(DAT_DIR+'toxref_exact_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k,s grid search over clusters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within cluster predictions\n",
    "cluster_predictions=[]\n",
    "for k in ks:\n",
    "    for s in ss: \n",
    "        for cluster in clusters:\n",
    "            chems=cluster['chems']\n",
    "            cluster_df=loael_neighbors_mean[(loael_neighbors_mean['target_sid'].isin(chems)) & loael_neighbors_mean['neighbor_sid'].isin(chems)]\n",
    "            for sid,group in cluster_df.groupby('target_sid'):\n",
    "                prediction={category+'_p':wtavg(group,category,k,s) for category in categories}\n",
    "                prediction['dsstox_sid']=sid\n",
    "                prediction['k']=k\n",
    "                prediction['s']=s\n",
    "                prediction['cluster']=cluster['cl_id']\n",
    "                cluster_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df=pd.DataFrame(cluster_predictions)\n",
    "cluster_prediction_df=cluster_prediction_df.merge(loael_agg_mean,left_on='dsstox_sid',right_index=True)\n",
    "cluster_prediction_df.to_csv(DAT_DIR+'cluster_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_predictions=[]\n",
    "for k in ks:\n",
    "    for s in ss:\n",
    "        for cluster in clusters:\n",
    "            chems=cluster['chems']\n",
    "            cluster_df=loael_neighbors_mean[(loael_neighbors_mean['target_sid'].isin(chems)) & loael_neighbors_mean['neighbor_sid'].isin(chems)]\n",
    "            for sid,group in cluster_df.groupby('target_sid'):\n",
    "                prediction={category+'_p':exact_k_wtavg(group,category,k,s) for category in categories}\n",
    "                prediction['dsstox_sid']=sid\n",
    "                prediction['k']=k\n",
    "                prediction['s']=s\n",
    "                prediction['cluster']=cluster['cl_id']\n",
    "                exactk_cluster_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_cluster_prediction_df=pd.DataFrame(exactk_cluster_predictions)\n",
    "exactk_cluster_prediction_df=exactk_cluster_prediction_df.merge(loael_agg_mean,left_on='dsstox_sid',right_index=True)\n",
    "exactk_cluster_prediction_df.to_csv(DAT_DIR+'exactk_cluster_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df=pd.read_csv(DAT_DIR+'cluster_ks_gridsearch.csv')\n",
    "exactk_cluster_prediction_df=pd.read_csv(DAT_DIR+'exactk_cluster_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster R2s with restricting predictions to within cluster for k=10 and s=.05\n",
    "i=1\n",
    "within_r2s=[]\n",
    "f=plt.figure(figsize=(12,300))\n",
    "for cluster in clusters:\n",
    "    chems=cluster['chems']\n",
    "    k=10\n",
    "    s=.05\n",
    "    cluster_df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems)) &\\\n",
    "                                    (cluster_prediction_df['k']==k) & (cluster_prediction_df['s']==s)]\n",
    "    cluster_df=cluster_df[['systemic','systemic_p']]\n",
    "    cluster_df=plot_worthy(cluster_df)\n",
    "    if cluster_df.empty:\n",
    "        continue\n",
    "    plt.subplot(50,2,i)\n",
    "    i+=1\n",
    "    plt.scatter(cluster_df['systemic_p'],cluster_df['systemic'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Cluster ' + str(cluster['cl_id']) + ' systemic BMD Predictions')\n",
    "    plt.annotate('R2='+str(round(r2_score(cluster_df['systemic'],cluster_df['systemic_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "    plt.annotate('n='+str(len(cluster_df)),xy=(.8,-.2),xycoords='axes fraction')\n",
    "    within_r2s.append({'cl_id':cluster['cl_id'],'R2':r2_score(cluster_df['systemic'],cluster_df['systemic_p']),'size':len(cluster_df)})\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_r2_df=pd.DataFrame(within_r2s)\n",
    "within_r2_df=within_r2_df.sort_values('R2',ascending=False)\n",
    "r2_df=within_r2_df.merge(loael_r2_df,on='cl_id',suffixes=('_within',''))\n",
    "r2_df['comp']=(r2_df['R2_within']>r2_df['R2'])*1\n",
    "r2_df=r2_df.set_index('cl_id')\n",
    "r2_df=r2_df.sort_values(['R2'],ascending=False)\n",
    "sum(r2_df['comp'])\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_grid_r2s={}\n",
    "cluster_grid_ns={}\n",
    "for cluster in clusters:\n",
    "    chems=cluster['chems']\n",
    "    clid=int(cluster['cl_id'])\n",
    "    cluster_grid_r2s[clid]=np.empty([len(ks),len(ss)])\n",
    "    cluster_grid_ns[clid]=np.empty([len(ks),len(ss)])\n",
    "    for (k,s),group in cluster_prediction_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems))\\\n",
    "                                 & (cluster_prediction_df['s']==s) & (cluster_prediction_df['k']==k)]\n",
    "        df=df[['systemic','systemic_p']]\n",
    "        df=plot_worthy(df)\n",
    "        if df.empty:\n",
    "            cluster_grid_r2s[clid][k_index,s_index]=np.nan\n",
    "            cluster_grid_ns[clid][k_index,s_index]=0   \n",
    "            continue\n",
    "        cluster_grid_r2s[clid][k_index,s_index]=r2_score(df['systemic'],df['systemic_p'])\n",
    "        cluster_grid_ns[clid][k_index,s_index]=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    if cluster['cl_id']=='24':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "s=.05\n",
    "df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems))\\\n",
    "                                 & (cluster_prediction_df['s']==s) & (cluster_prediction_df['k']==k)]\n",
    "#df=df[['systemic','systemic_p']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_grid_ns['6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format',lambda x: '%.3f' % x):\n",
    "    for clid,grid in cluster_grid_r2s.iteritems():\n",
    "        print(clid)\n",
    "        print(str(cluster_grid_ns[clid].max())+ ' predictions')\n",
    "        pd.DataFrame(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "i=1\n",
    "fig=plt.figure(figsize=(12,300))\n",
    "for clid,cluster_grid_r2 in cluster_grid_r2s.iteritems():\n",
    "    fig.suptitle('k,s grid search for up to k neighbors',fontsize=20)\n",
    "    ax=fig.add_subplot(50,2,i,projection='3d')\n",
    "    #ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    i+=1\n",
    "    ax.plot_surface(X,Y,cluster_grid_r2)\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "    ax.set_title('Cluster '+ clid )\n",
    "plt.subplots_adjust()\n",
    "plt.savefig(FIG_DIR+'cluster_ksgrid_uptok')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for clid,cluster_grid_r2 in cluster_grid_r2s.iteritems():\n",
    "    fig=plt.figure(figsize=(8,6))\n",
    "    plt.title('k,s grid search for up to k neighbors for cluster ' + str(clid),fontsize=20)\n",
    "    #ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    plt.contour(X,Y,cluster_grid_r2)\n",
    "    plt.ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    plt.xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    #ax.set_title('Cluster '+ clid )\n",
    "    plt.show()\n",
    "#plt.savefig(FIG_DIR+'cluster_ksgrid_uptok')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster_grid_r2s.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "i=1\n",
    "fig=plt.figure(figsize=(12,300))\n",
    "for clid,cluster_grid_r2 in exactk_cluster_grid_r2s.iteritems():\n",
    "    fig.suptitle('k,s grid search for exactly k neighbors',fontsize=20)\n",
    "    ax=fig.add_subplot(2,50,i,projection='3d')\n",
    "    #ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    i+=1\n",
    "    ax.plot_surface(X,Y,cluster_grid_r2)\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "    ax.set_title('Cluster '+ clid )\n",
    "plt.subplots.adjust()\n",
    "plt.savefig(FIG_DIR+'cluster_ksgrid_exactk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EPA Categories</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "op_dict={\n",
    "    'GreaterThan': op.gt,\n",
    "    'GreaterThanOrEqualTo': op.ge,\n",
    "    'LessThan': op.lt,\n",
    "    'LessThanOrEqualTo': op.le\n",
    "}\n",
    "prop_dict={\n",
    "    'log Kow':'logp',\n",
    "    'Molecular Weight':'mol_weight',\n",
    "    'Molecular weight':'mol_weight',\n",
    "    'Water Solubility': 'ws'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ppb(x): #OPERA results stored as mol/L\n",
    "    ws=x['ws']\n",
    "    mol_weight=x['mol_weight']\n",
    "    return ws*mol_weight*10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(DAT_DIR+'../category_tests.dill') as f:\n",
    "    category_tests=dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_smiles=dsstox.find({'dsstox_sid':{'$in':loael_sids}},{'_id':0,'dsstox_sid':1,'smiles':1})\n",
    "smiles_dict={record['dsstox_sid']:record['smiles'] for record in loael_smiles}\n",
    "loael_logp=physprop.find({'dsstox_sid':{'$in':loael_sids}},{'_id':0,'dsstox_sid':1,'predicted_props.OPERA_LogP':1})\n",
    "logp_dict={record['dsstox_sid']:record.get('predicted_props',{})['OPERA_LogP'][0] for record in loael_logp \\\n",
    "           if 'OPERA_LogP' in record.get('predicted_props',{}) and record.get('dsstox_sid',None)}\n",
    "loael_ws=physprop.find({'dsstox_sid':{'$in':loael_sids}},{'_id':0,'dsstox_sid':1,'predicted_props.OPERA_WS':1})\n",
    "ws_dict={record['dsstox_sid']:record.get('predicted_props',{})['OPERA_WS'][0] for record in loael_ws \\\n",
    "           if 'OPERA_WS' in record.get('predicted_props',{}) and record.get('dsstox_sid',None)}\n",
    "loael_weight=dsstox.find({'dsstox_sid':{'$in':loael_sids}})\n",
    "weight_dict={record['dsstox_sid']:record['mol_weight'] for record in loael_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "sids=set(logp_dict.keys())&set(ws_dict.keys())&set(weight_dict.keys())\n",
    "records=[]\n",
    "for sid in sids:\n",
    "    records.append({'dsstox_sid':sid,'smiles':smiles_dict[sid],'logp':logp_dict[sid],'ws':ws_dict[sid],'mol_weight':weight_dict[sid],'mol':Chem.MolFromSmiles(smiles_dict[sid])})\n",
    "records=[record for record in records if record['mol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for record in records:\n",
    "    if not record['mol']:\n",
    "        continue\n",
    "    epa_categories=sorted([category for category,test in category_tests.iteritems() if test(record)])\n",
    "    if 'Neutral Organics' in epa_categories and len(epa_categories)>1:\n",
    "        epa_categories.remove('Neutral Organics')\n",
    "    record['categories']=tuple(epa_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count=Counter(record['categories'] for record in records)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "search_spaces=defaultdict(list)\n",
    "for record in records:\n",
    "    search_spaces[record['categories']].append(record['dsstox_sid'])\n",
    "import pickle\n",
    "with open(DAT_DIR+'search_spaces.pkl','w') as f:\n",
    "    pickle.dump(search_spaces,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors_l=[]\n",
    "for record in records:\n",
    "    sid=record['dsstox_sid']\n",
    "    search_space=search_spaces[record['categories']][:]\n",
    "    if len(search_space)==1:\n",
    "        continue\n",
    "    search_space.remove(sid)\n",
    "    sid_neighbors=searchCollByFP(sid,s0=.05,SID=search_space,DB=DB,col='chemotypes',fpn='chemotypes')\n",
    "    if sid_neighbors:\n",
    "        for neighbor in sid_neighbors:\n",
    "            neighbor['target_sid']=sid\n",
    "            neighbor['neighbor_sid']=neighbor.pop('dsstox_sid')\n",
    "        category_neighbors_l=category_neighbors_l+sid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors=pd.DataFrame(category_neighbors_l)\n",
    "category_neighbors=category_neighbors[category_neighbors['target_sid']!=category_neighbors['neighbor_sid']]\n",
    "category_neighbors=category_neighbors.merge(loael_agg_mean,left_on='neighbor_sid',right_index=True)\n",
    "category_neighbors=category_neighbors.sort_values('jaccard',ascending=False)\n",
    "category_neighbors.to_csv(DAT_DIR+'category_neighbors_chemotypes.csv',index=False)\n",
    "category_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in category_neighbors.groupby('target_sid'):\n",
    "    predictions[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions=pd.DataFrame(predictions.values(),index=predictions.keys())\n",
    "category_predictions=category_predictions.merge(loael_agg_mean,right_index=True,left_index=True)\n",
    "category_predictions.to_csv(DAT_DIR+'category_predictions_chemotypes.csv')\n",
    "category_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
