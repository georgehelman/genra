{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import sys\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP = '/'.join(os.getcwd().split('/')[:-2])+'/'\n",
    "LIB = TOP+'lib'\n",
    "if not LIB in sys.path: \n",
    "    sys.path.insert(0,LIB)\n",
    "\n",
    "DAT_DIR = TOP + 'data/toxref/'\n",
    "FIG_DIR = TOP + 'figs/toxref/'\n",
    "\n",
    "from rax.genrapred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongocon=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_dev_v4\")\n",
    "DB=mongocon['genra_dev_v4']\n",
    "dsstox=DB['compound']\n",
    "toxref=DB['toxrefdb2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worthy(pdobject):\n",
    "    if isinstance(pdobject,pd.core.series.Series):\n",
    "        pdobject=pdobject[pd.notnull(pdobject)]\n",
    "        pdobject=pdobject[pdobject!=np.inf]\n",
    "        return pdobject\n",
    "    elif isinstance(pdobject,pd.core.frame.DataFrame):\n",
    "        pdobject=pdobject[pdobject.notnull().all(axis='columns')]\n",
    "        pdobject=pdobject[(pdobject!=np.inf).all(axis=1)]\n",
    "        return pdobject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_k_wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if len(df)<k:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtvar(df,name,k):\n",
    "    df=df[(df[name].notnull()) & (df[name]!=np.inf)].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return sum([weights[i]**2*values[i] for i in range(len(values))])/sum(weights)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_df=pd.read_csv(DAT_DIR+'loael.csv')\n",
    "lel_df=pd.read_csv(DAT_DIR+'lel.csv')\n",
    "loael_agg=pd.read_csv(DAT_DIR+'loaelagg.csv',index_col='dsstox_sid')\n",
    "lel_agg=pd.read_csv(DAT_DIR+'lelagg.csv',index_col='dsstox_sid')\n",
    "loael_sids=list(set(loael_agg.index.values))\n",
    "lel_sids=list(set(lel_agg.index.values))\n",
    "loael_neighbors=pd.read_csv(DAT_DIR+'loael_neighbors.csv')\n",
    "lel_neighbors=pd.read_csv(DAT_DIR+'lel_neighbors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=list(loael_agg.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in loael_neighbors.groupby('target_sid'):\n",
    "        predictions[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_predictions=pd.DataFrame(predictions.values(),index=predictions.keys())\n",
    "loael_predictions=loael_predictions.merge(loael_agg,right_index=True,left_index=True)\n",
    "len(loael_predictions)\n",
    "loael_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "plt.suptitle('Min Aggregation Prediction')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=loael_predictions[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in lel_neighbors.groupby('target_sid'):\n",
    "        predictions1[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lel_predictions=pd.DataFrame(predictions1.values(),index=predictions1.keys())\n",
    "lel_predictions=lel_predictions.merge(lel_agg,right_index=True,left_index=True)\n",
    "lel_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=lel_predictions[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BMDs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_agg=pd.read_csv(DAT_DIR+'bmdagg.csv')\n",
    "bmd_neighbors=pd.read_csv(DAT_DIR+'bmd_neighbors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions={}\n",
    "k=10\n",
    "s=.05\n",
    "for index,group in bmd_neighbors.groupby(['target_sid','bmr_type']):\n",
    "    predictions[index]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_predictions=pd.DataFrame(predictions.values(),index=pd.MultiIndex.from_tuples(predictions.keys(),names=['dsstox_sid','bmr_type']))\n",
    "bmd_predictions=bmd_predictions.merge(bmd_agg,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,16))\n",
    "for bmr_type,group in bmd_predictions.reset_index(1).groupby('bmr_type'):\n",
    "    for category in categories:\n",
    "        df=group[[category,category+'_p']]\n",
    "        df=df[df.notnull().all(axis='columns')]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        plt.subplot(4,2,i)\n",
    "        i+=1\n",
    "        plt.scatter(df[category],df[category+'_p'])\n",
    "        plt.title(category+ ' ' + bmr_type+ ' predictions')\n",
    "        plt.xlabel('True')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.90),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.4,hspace=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_gt9=bmd_neighbors[bmd_neighbors['jaccard']>.9]['target_sid'].unique() #Targets with atleast 1 neighbors >.3\n",
    "len(bmd_neighbors['target_sid'].unique())\n",
    "len(bmd_gt9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(series):\n",
    "    diff=[abs(series[category]-series[category+'_p']) for category in categories if not np.isnan(series[category])]\n",
    "    return sum(diff)/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMD best results\n",
    "ranked_bmds=bmd_predictions.copy()\n",
    "ranked_bmds['rank']=ranked_bmds.apply(ranker,axis='columns')\n",
    "ranked_bmds=ranked_bmds.loc[bmd_gt9]\n",
    "ranked_bmds=ranked_bmds.sort_values('rank')\n",
    "ranked_bmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMD good prediction\n",
    "sid='DTXSID8023848'\n",
    "bmr_type='rd'\n",
    "dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})\n",
    "row=bmd_predictions.loc[sid,bmr_type]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "bmd_neighbors[(bmd_neighbors['target_sid']==sid) & (bmd_neighbors['bmr_type']==bmr_type) & (pd.notnull(bmd_neighbors['systemic']))].iloc[0:10]['neighbor_sid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMD bad prediction\n",
    "sid='DTXSID4032459'\n",
    "bmr_type='sd'\n",
    "dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})\n",
    "row=bmd_predictions.loc[sid,bmr_type]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "nhood=bmd_neighbors[(bmd_neighbors['target_sid']==sid) & (bmd_neighbors['bmr_type']==bmr_type) & (pd.notnull(bmd_neighbors['systemic']))].iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BMD/LOAEL neighborhood comparison</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(diff):\n",
    "    if abs(diff)==0: return '='\n",
    "    elif diff<.0: return '<'\n",
    "    elif diff>.0: return '>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_sim=loael_neighbors.pivot_table(index='target_sid',values='jaccard',aggfunc=lambda x: x[0:2].mean())\n",
    "bmd_sim=bmd_neighbors.pivot_table(index='target_sid',values='jaccard',aggfunc=lambda x: x[0:2].mean())\n",
    "sims=loael_sim.merge(bmd_sim,left_index=True,right_index=True)\n",
    "sims.columns=['loael','bmd']\n",
    "sims['diff']=sims['loael']-sims['bmd']\n",
    "sims['loael_comp']=sims['diff'].map(compare)\n",
    "sims.head()\n",
    "sims.describe()\n",
    "sims['loael_comp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sims['loael'],sims['bmd'])\n",
    "plt.title('BMD vs LOAEL neighborhood similarity')\n",
    "plt.ylabel('BMD')\n",
    "plt.xlabel('LOAEL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsstox.find_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mean Aggregation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean=pd.read_csv(DAT_DIR+'loael_agg_mean.csv',index_col='dsstox_sid')\n",
    "loael_agg_sd=pd.read_csv(DAT_DIR+'loael_agg_sd.csv',index_col='dsstox_sid')\n",
    "loael_neighbors_mean=pd.read_csv(DAT_DIR+'loael_neighbors_mean.csv')\n",
    "loael_neighbors_sd=pd.read_csv(DAT_DIR+'loael_neighbors_sd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mean={}\n",
    "k=10\n",
    "s=.05\n",
    "for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "    predictions_mean[sid]={category+'_p':wtavg(group,category,k,s) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sd={}\n",
    "k=10\n",
    "for sid,group in loael_neighbors_sd.groupby('target_sid'):\n",
    "    predictions_sd[sid]={category:wtvar(group,category,k) for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_predictions_mean=pd.DataFrame(predictions_mean.values(),index=predictions_mean.keys())\n",
    "loael_predictions_mean=loael_predictions_mean.merge(loael_agg_mean,right_index=True,left_index=True)\n",
    "len(loael_predictions_mean)\n",
    "loael_predictions_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Mean Aggregation Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=loael_predictions_mean[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhood_sims=loael_neighbors_mean.pivot_table(index='target_sid',values='jaccard',aggfunc=lambda x: x[0:2].mean())\n",
    "nhood_sims['sqres']=(loael_predictions_mean['systemic']-loael_predictions_mean['systemic_p'])**2\n",
    "nhood_sims=nhood_sims[pd.notnull(nhood_sims['sqres'])]\n",
    "nhood_sims=nhood_sims.sort_values('sqres',ascending=False).iloc[12:len(nhood_sims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "av_sims={}\n",
    "for sid,group in loael_neighbors_mean.groupby('target_sid'):\n",
    "    av_sim=group.iloc[0:2]['jaccard'].mean()\n",
    "    av_sims[sid]=av_sim\n",
    "loael_accuracy=loael_predictions_mean.copy()\n",
    "loael_accuracy['systemic_accuracy']=abs(loael_accuracy['systemic']-loael_accuracy['systemic_p'])\n",
    "loael_accuracy['av_sim']=loael_accuracy.index.map(av_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "df=loael_accuracy.copy()[['av_sim','systemic_accuracy']]\n",
    "df=df.loc[plot_worthy(df['systemic_accuracy']).index.values]\n",
    "x=df['av_sim']\n",
    "y=df['systemic_accuracy']\n",
    "\n",
    "nullfmt=NullFormatter()\n",
    "left,width=.1,.65\n",
    "bottom, height = .1,.65\n",
    "bottom_h = bottom + height +.02\n",
    "left_h = left + width + .02\n",
    "rect_scatter = [left,bottom,width,height]\n",
    "rect_histx = [left,bottom_h,width,.2]\n",
    "rect_histy = [left_h,bottom,.2,height]\n",
    "plt.figure(1, figsize=(8,8))\n",
    "\n",
    "axScatter=plt.axes(rect_scatter)\n",
    "axHistx = plt.axes(rect_histx)\n",
    "axHisty = plt.axes(rect_histy)\n",
    "axHistx.xaxis.set_major_formatter(nullfmt)\n",
    "axHisty.yaxis.set_major_formatter(nullfmt)\n",
    "\n",
    "axScatter.scatter(x,y,label=\"\")\n",
    "X=np.array([x**i for i in range(0,3)]).T\n",
    "order3=LinearRegression()\n",
    "order3.fit(X,y)\n",
    "x_space=np.linspace(0,1,100)\n",
    "x_dummy=np.array([x_space**i for i in range(0,3)]).T\n",
    "axScatter.plot(x_space,order3.predict(x_dummy),color='orange',linestyle='--',linewidth=3, label='fit')\n",
    "axScatter.legend(loc='upper left')\n",
    "\n",
    "axHistx.hist(x)\n",
    "axHisty.hist(y,orientation='horizontal')\n",
    "axHistx.set_xlim(axScatter.get_xlim())\n",
    "axHisty.set_ylim(axScatter.get_ylim())\n",
    "\n",
    "axHistx.set_title('Systemic residual vs similarity')\n",
    "axScatter.set_xlabel('Average similarity across neighborhood')\n",
    "axScatter.set_ylabel('Systemic residual')\n",
    "plt.savefig(FIG_DIR+'simvsres',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Further LOAEL Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt9=loael_neighbors_mean[loael_neighbors_mean['jaccard']>.9]['target_sid'].unique() #Targets with atleast 1 neighbors >.9\n",
    "len(loael_neighbors_mean['target_sid'].unique())\n",
    "len(gt9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(series):\n",
    "    diff=[abs(series[category]-series[category+'_p']) for category in categories if not np.isnan(series[category])]\n",
    "    return sum(diff)/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loael best results\n",
    "ranked_loaels=loael_predictions_mean.copy()\n",
    "ranked_loaels['rank']=ranked_loaels.apply(ranker,axis='columns')\n",
    "ranked_loaels=ranked_loaels.loc[gt9]\n",
    "ranked_loaels=ranked_loaels.sort_values('rank')\n",
    "ranked_loaels['mol_weight']=ranked_loaels.index.map(weights)\n",
    "ranked_loaels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':loael_sids}})}\n",
    "def convert_back(lm,weight):\n",
    "    return 10**-lm*1000*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good prediction\n",
    "sid='DTXSID5020607'\n",
    "row=loael_predictions_mean.loc[sid]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['developmental']))].iloc[0:10]\n",
    "nhood=loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['systemic']))].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad prediction\n",
    "sid='DTXSID5031131'\n",
    "dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})\n",
    "row=loael_predictions_mean.loc[sid]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "nhood=loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['systemic']))].iloc[0:10]\n",
    "','.join(nhood['neighbor_sid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genra_predict(ndf,tdf,category,k,s):\n",
    "    predictions={}\n",
    "    for sid,group in ndf.groupby(['target_sid']):\n",
    "        predictions[sid]=wtavg(group,category,k,s)\n",
    "    prediction_df=pd.DataFrame(predictions.values(),index=predictions.keys(),columns=[category+'_p'])\n",
    "    prediction_df=prediction_df.merge(tdf,right_index=True,left_index=True)\n",
    "    prediction_df=prediction_df[[category,category+'_p']]\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids=loael_neighbors['target_sid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "i=0\n",
    "r2s=[]\n",
    "while i<100:\n",
    "    train,test=train_test_split(sids,test_size=.1)\n",
    "    test_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(test))]\n",
    "    k=10\n",
    "    s=.05\n",
    "    category='systemic'\n",
    "    tts_predictions=plot_worthy(genra_predict(test_neighbors,loael_agg,category,k,s))\n",
    "    r2s.append(r2_score(tts_predictions[category],tts_predictions[category+'_p']))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r2s)\n",
    "plt.axvline(x=.24,color='orange',label='Full Dataset')\n",
    "plt.xlabel('R2 score')\n",
    "plt.title('R2 scores for 100 90-10 train-test splits')\n",
    "plt.savefig(FIG_DIR+'r2hist')\n",
    "plt.legend(loc='best',fontsize=11)\n",
    "plt.savefig(FIG_DIR+'r2hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemic_sids=list(loael_agg.sample(frac=1)[pd.notnull(loael_agg['systemic'])].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "percents=[n*.01 for n in range(1,26,1)]\n",
    "train_r2s=[]\n",
    "test_r2s=[]\n",
    "for percent in percents:\n",
    "    for i in range(0,50):\n",
    "        train_r2s_it=[]\n",
    "        test_r2s_it=[]\n",
    "        train,test=train_test_split(sids,test_size=percent)\n",
    "        test_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(test))]\n",
    "        train_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(train))]\n",
    "        k=10\n",
    "        s=.05\n",
    "        category='systemic'\n",
    "        test_df=plot_worthy(genra_predict(test_neighbors,loael_agg,category,k,s))\n",
    "        train_df=plot_worthy(genra_predict(train_neighbors,loael_agg,category,k,s))\n",
    "        test_r2s_it.append(r2_score(test_df[category],test_df[category+'_p']))\n",
    "        train_r2s_it.append(r2_score(train_df[category],train_df[category+'_p']))\n",
    "    test_r2s.append(np.mean(test_r2s_it))\n",
    "    train_r2s.append(np.mean(train_r2s_it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=plot_worthy(loael_predictions_mean[['systemic','systemic_p']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(test_r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(range(0,25),test_r2s,label='test R2')\n",
    "ax.plot(range(0,25),train_r2s,label='train R2')\n",
    "df=plot_worthy(loael_predictions_mean[['systemic','systemic_p']])\n",
    "base_r2=r2_score(df['systemic'],df['systemic_p'])\n",
    "ax.axhline(y=base_r2,label='base R2',ls='--',color='black')\n",
    "ax.set_title('Learning Curve (Systemic)')\n",
    "ax.set_xlabel('Training set size (percent)')\n",
    "ax.set_ylabel('R2')\n",
    "ax.legend(loc=0)\n",
    "plt.subplots_adjust()\n",
    "plt.savefig(FIG_DIR+'learning_curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cluster Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(DAT_DIR+'clusters.pkl') as f:\n",
    "    clusters=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without restricting neighbors to be in same cluster\n",
    "i=1\n",
    "r2s=[]\n",
    "for cluster in clusters:\n",
    "    f=plt.figure(figsize=(12,300))\n",
    "    chems=cluster['chems']\n",
    "    try:\n",
    "        df=loael_predictions_mean.loc[chems]\n",
    "    except:\n",
    "        continue    \n",
    "    df=df[['systemic','systemic_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    plt.subplot(50,2,i)\n",
    "    i+=1\n",
    "    plt.scatter(df['systemic'],df['systemic_p'])\n",
    "    ax_min=df.values.min()-.1\n",
    "    ax_max=df.values.max()+.1\n",
    "    plt.xlim(ax_min,ax_max)\n",
    "    plt.ylim(ax_min,ax_max)\n",
    "    plt.title('Cluster ' + str(cluster['cl_id']) + 'systemic LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df['systemic'],df['systemic_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "    plt.annotate('n='+str(len(df)),xy=(.8,-.2),xycoords='axes fraction')\n",
    "    r2s.append({'cl_id':cluster['cl_id'],'R2':r2_score(df['systemic'],df['systemic_p']),'size':len(df)})\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_r2_df=pd.DataFrame(r2s)\n",
    "loael_r2_df=loael_r2_df.sort_values('R2',ascending=False)\n",
    "loael_r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_prediction_df=pd.read_csv(DAT_DIR+'cluster_ks_gridsearch.csv')\n",
    "exactk_cluster_prediction_df=pd.read_csv(DAT_DIR+'exactk_cluster_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster R2s with restricting predictions to within cluster for k=10 and s=.05\n",
    "i=1\n",
    "within_r2s=[]\n",
    "f=plt.figure(figsize=(12,300))\n",
    "for cluster in clusters:\n",
    "    chems=cluster['chems']\n",
    "    k=10\n",
    "    s=.05\n",
    "    cluster_df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems)) &\\\n",
    "                                    (cluster_prediction_df['k']==k) & (cluster_prediction_df['s']==s)]\n",
    "    cluster_df=cluster_df[['systemic','systemic_p']]\n",
    "    cluster_df=plot_worthy(cluster_df)\n",
    "    if cluster_df.empty:\n",
    "        continue\n",
    "    plt.subplot(50,2,i)\n",
    "    i+=1\n",
    "    plt.scatter(cluster_df['systemic_p'],cluster_df['systemic'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Cluster ' + str(cluster['cl_id']) + ' systemic BMD Predictions')\n",
    "    plt.annotate('R2='+str(round(r2_score(cluster_df['systemic'],cluster_df['systemic_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "    plt.annotate('n='+str(len(cluster_df)),xy=(.8,-.2),xycoords='axes fraction')\n",
    "    within_r2s.append({'cl_id':cluster['cl_id'],'R2':r2_score(cluster_df['systemic'],cluster_df['systemic_p']),'size':len(cluster_df)})\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_r2_df=pd.DataFrame(within_r2s)\n",
    "within_r2_df=within_r2_df.sort_values('R2',ascending=False)\n",
    "r2_df=within_r2_df.merge(loael_r2_df,on='cl_id',suffixes=('_within',''))\n",
    "r2_df['comp']=(r2_df['R2_within']>r2_df['R2'])*1\n",
    "r2_df=r2_df.set_index('cl_id')\n",
    "r2_df=r2_df.sort_values(['R2'],ascending=False)\n",
    "sum(r2_df['comp'])\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMD cluster analysis without restricting neighbors\n",
    "i=1\n",
    "r2s=[]\n",
    "f=plt.figure(figsize=(12,300))\n",
    "for cluster in clusters: \n",
    "    chems=cluster['chems']\n",
    "    try:\n",
    "        df=bmd_predictions.loc[chems]\n",
    "    except:\n",
    "        continue    \n",
    "    df=df[['systemic','systemic_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    plt.subplot(50,2,i)\n",
    "    i+=1\n",
    "    plt.scatter(df['systemic'],df['systemic_p'])\n",
    "    ax_min=df.values.min()-.1\n",
    "    ax_max=df.values.max()+.1\n",
    "    plt.xlim(ax_min,ax_max)\n",
    "    plt.ylim(ax_min,ax_max)\n",
    "    plt.title('Cluster ' + str(cluster['cl_id']) + 'systemic BMD Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df['systemic'],df['systemic_p']),2)),xy=(.8,-.15),xycoords='axes fraction')\n",
    "    plt.annotate('n='+str(len(df)),xy=(.8,-.2),xycoords='axes fraction')\n",
    "    r2s.append({'cl_id':cluster['cl_id'],'R2':r2_score(df['systemic'],df['systemic_p']),'size':len(df)})\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_r2_df=pd.DataFrame(r2s)\n",
    "bmd_r2_df=bmd_r2_df.sort_values('R2',ascending=False)\n",
    "bmd_r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df=loael_r2_df.merge(bmd_r2_df,on='cl_id',suffixes=('loael_','bmd_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k,s grid search for LOAELS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "ks=range(1,20)\n",
    "ss=[round(s/20,2) for s in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df=pd.read_csv(DAT_DIR+'toxref_ks_gridsearch.csv')\n",
    "prediction_df=prediction_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dfs=[prediction_df[[category,category+'_p','k','s']] for category in categories]\n",
    "for category_df in category_dfs:\n",
    "    category_df.columns=['true','predicted','k','s']\n",
    "global_df=pd.concat(category_dfs)\n",
    "global_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_grid_r2s=np.empty([len(ks),len(ss)])\n",
    "global_grid_ns=np.empty([len(ks),len(ss)])\n",
    "for (k,s),group in global_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        group=group[group.notnull().all(axis='columns')]\n",
    "        group=group[(group!=np.inf).all(axis=1)]\n",
    "        global_grid_ns[k_index,s_index]=len(group)\n",
    "        global_grid_r2s[k_index,s_index]=r2_score(group['true'],group['predicted'])\n",
    "global_grid_r2s=pd.DataFrame(global_grid_r2s,index=ks,columns=ss)\n",
    "global_grid_ns=pd.DataFrame(global_grid_ns,index=ks,columns=ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_r2s={category:np.empty([len(ks),len(ss)]) for category in categories}\n",
    "grid_ns={category:np.empty([len(ks),len(ss)]) for category in categories}\n",
    "for category in categories:\n",
    "    for (k,s),group in prediction_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        df=group[[category,category+'_p']]\n",
    "        df=df[df.notnull().all(axis='columns')]\n",
    "        df=df[(df!=np.inf).all(axis=1)]\n",
    "        grid_ns[category][k_index,s_index]=len(df)\n",
    "        grid_r2s[category][k_index,s_index]=r2_score(df[category],df[category+'_p'])\n",
    "    grid_r2s[category]=pd.DataFrame(grid_r2s[category],index=ks,columns=ss)\n",
    "    grid_ns[category]=pd.DataFrame(grid_ns[category],index=ks,columns=ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(30,15))\n",
    "fig.suptitle('k,s grid search for up to k neighbors',fontsize=20)\n",
    "ax=fig.add_subplot(2,3,1,projection='3d')\n",
    "ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "ax.plot_surface(X,Y,global_grid_r2s)\n",
    "ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "ax.set_zlabel('R2')\n",
    "i=2\n",
    "for category in categories:\n",
    "    ax=fig.add_subplot(2,3,i,projection='3d')\n",
    "    i+=1\n",
    "    ax.text2D(.5,.95,category,transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    ax.plot_surface(X,Y,grid_r2s[category])\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "plt.savefig(FIG_DIR+'ksgrid_uptok')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_grid_ns=global_grid_ns.astype(int)\n",
    "global_grid_ns\n",
    "for category in categories:\n",
    "    grid_ns[category]=grid_ns[category].astype(int)\n",
    "    grid_ns[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_k_df=pd.read_csv(DAT_DIR+'toxref_exact_ks_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dfs=[exact_k_df[[category,category+'_p','k','s']] for category in categories]\n",
    "for category_df in category_dfs:\n",
    "    category_df.columns=['true','predicted','k','s']\n",
    "exactk_df=pd.concat(category_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_global_grid_r2s=np.empty([len(ks),len(ss)])\n",
    "exactk_global_grid_ns=np.empty([len(ks),len(ss)])\n",
    "for (k,s),group in exactk_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        group=group[group.notnull().all(axis='columns')]\n",
    "        group=group[(group!=np.inf).all(axis=1)]\n",
    "        exactk_global_grid_ns[k_index,s_index]=len(group)\n",
    "        grid_r2s={category:np.empty([len(ks),len(ss)]) for category in categories}\n",
    "grid_ns={category:np.empty([len(ks),len(ss)]) for category in categories}\n",
    "            continue\n",
    "        exactk_global_grid_r2s[k_index,s_index]=r2_score(group['true'],group['predicted'])\n",
    "exactk_global_grid_r2s=pd.DataFrame(exactk_global_grid_r2s,index=ks,columns=ss)\n",
    "exactk_global_grid_ns=pd.DataFrame(exactk_global_grid_ns,index=ks,columns=ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_grid_r2s={category:np.empty([len(ks),len(ss)]) for category in categories}\n",
    "exactk_grid_ns={category:np.empty([len(ks),len(ss)]) for category in categories}\n",
    "for category in categories:\n",
    "    for (k,s),group in exact_k_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        df=group[[category,category+'_p']]\n",
    "        df=df[df.notnull().all(axis='columns')]\n",
    "        df=df[(df!=np.inf).all(axis=1)]\n",
    "        if df.empty:\n",
    "            exactk_grid_ns[category][k_index,s_index]=0\n",
    "            exactk_grid_r2s[category][k_index,s_index]=np.nan\n",
    "            continue\n",
    "        exactk_grid_ns[category][k_index,s_index]=len(df)\n",
    "        exactk_grid_r2s[category][k_index,s_index]=r2_score(df[category],df[category+'_p'])\n",
    "    exactk_grid_r2s[category]=pd.DataFrame(exactk_grid_r2s[category],index=ks,columns=ss)\n",
    "    exactk_grid_ns[category]=pd.DataFrame(exactk_grid_ns[category],index=ks,columns=ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(30,15))\n",
    "fig.suptitle('k,s grid search for exactly k neighbors',fontsize=20)\n",
    "ax=fig.add_subplot(2,3,1,projection='3d')\n",
    "ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "ax.plot_surface(X,Y,exactk_global_grid_r2s[exactk_global_grid_ns>=30])\n",
    "ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "ax.set_zlabel('R2')\n",
    "i=2\n",
    "for category in categories:\n",
    "    ax=fig.add_subplot(2,3,i,projection='3d')\n",
    "    i+=1\n",
    "    ax.text2D(.5,.95,category,transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    ax.plot_surface(X,Y,exactk_grid_r2s[category][exactk_grid_ns[category]>=30])\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "plt.savefig(FIG_DIR+'ksgrid_exactk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactk_global_grid_ns=exactk_global_grid_ns.astype(int)\n",
    "print('Global')\n",
    "exactk_global_grid_ns\n",
    "for category in categories:\n",
    "    print(category)\n",
    "    exactk_grid_ns[category]=exactk_grid_ns[category].astype(int)\n",
    "    exactk_grid_ns[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(9,6))\n",
    "plt.subplot(2,3,1)\n",
    "ax=Axes3D(fig)\n",
    "ax.text2D(.5,.95,'n for exactly k neighbors for global',transform=ax.transAxes)\n",
    "X,Y=np.meshgrid(ss,ks)\n",
    "ax.plot_surface(X,Y,exactk_global_grid_ns)\n",
    "ax.set_ylabel('Maximum number of neighbors (k)')\n",
    "ax.set_xlabel('Similarity threshold (s)')\n",
    "ax.set_zlabel('n')\n",
    "i=2\n",
    "for category in categories:\n",
    "    fig=plt.figure(figsize=(9,6))\n",
    "    plt.subplot(2,3,i)\n",
    "    i+=1\n",
    "    ax=Axes3D(fig)\n",
    "    ax.text2D(.5,.95,'n for exactly k neighbors for ' + category,transform=ax.transAxes)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    ax.plot_surface(X,Y,exactk_grid_ns[category])\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)')\n",
    "    ax.set_xlabel('Similarity threshold (s)')\n",
    "    ax.set_zlabel('n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k,s grid search over clusters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_grid_r2s={}\n",
    "cluster_grid_ns={}\n",
    "for cluster in clusters:\n",
    "    chems=cluster['chems']\n",
    "    clid=int(cluster['cl_id'])\n",
    "    cluster_grid_r2s[clid]=np.empty([len(ks),len(ss)])\n",
    "    cluster_grid_ns[clid]=np.empty([len(ks),len(ss)])\n",
    "    for (k,s),group in cluster_prediction_df.groupby(['k','s']):\n",
    "        k_index=ks.index(k)\n",
    "        s_index=ss.index(round(s,2))\n",
    "        df=cluster_prediction_df[(cluster_prediction_df['dsstox_sid'].isin(chems))\\\n",
    "                                 & (cluster_prediction_df['s']==s) & (cluster_prediction_df['k']==k)]\n",
    "        df=df[['systemic','systemic_p']]\n",
    "        df=plot_worthy(df)\n",
    "        if df.empty:\n",
    "            cluster_grid_r2s[clid][k_index,s_index]=np.nan\n",
    "            cluster_grid_ns[clid][k_index,s_index]=0   \n",
    "            continue\n",
    "        cluster_grid_r2s[clid][k_index,s_index]=r2_score(df['systemic'],df['systemic_p'])\n",
    "        cluster_grid_ns[clid][k_index,s_index]=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_r2_df=pd.DataFrame(within_r2s)\n",
    "within_r2_df=within_r2_df.sort_values('R2',ascending=False)\n",
    "r2_df=within_r2_df.merge(loael_r2_df,on='cl_id',suffixes=('_within',''))\n",
    "r2_df['comp']=(r2_df['R2_within']>r2_df['R2'])*1\n",
    "r2_df=r2_df.set_index('cl_id')\n",
    "r2_df=r2_df.sort_values(['R2'],ascending=False)\n",
    "sum(r2_df['comp'])\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_neighbors_mean[loael_neighbors_mean['target_sid']=='DTXSID4020240']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=[cluster for cluster in clusters if cluster['cl_id']=='17'][0]\n",
    "chems=cluster['chems']\n",
    "cluster_df=loael_neighbors_mean[(loael_neighbors_mean['target_sid'].isin(chems)) & loael_neighbors_mean['neighbor_sid'].isin(chems)]\n",
    "cluster_df\n",
    "for sid,group in cluster_df.groupby('target_sid'):\n",
    "                prediction={category+'_p':wtavg(group,category,k,s) for category in categories}\n",
    "                prediction['dsstox_sid']=sid\n",
    "                prediction['k']=k\n",
    "                prediction['s']=s\n",
    "                prediction['cluster']=cluster['cl_id']\n",
    "                prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format',lambda x: '%.3f' % x):\n",
    "    for clid,grid in cluster_grid_r2s.iteritems():\n",
    "        print(clid)\n",
    "        print(str(cluster_grid_ns[clid].max())+ ' predictions')\n",
    "        pd.DataFrame(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "i=1\n",
    "fig=plt.figure(figsize=(12,300))\n",
    "for clid,cluster_grid_r2 in cluster_grid_r2s.iteritems():\n",
    "    fig.suptitle('k,s grid search for up to k neighbors',fontsize=20)\n",
    "    ax=fig.add_subplot(50,2,i,projection='3d')\n",
    "    #ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    i+=1\n",
    "    ax.plot_surface(X,Y,cluster_grid_r2)\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "    ax.set_title('Cluster '+ clid )\n",
    "plt.subplots_adjust()\n",
    "plt.savefig(FIG_DIR+'cluster_ksgrid_uptok')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for clid,cluster_grid_r2 in cluster_grid_r2s.iteritems():\n",
    "    fig=plt.figure(figsize=(8,6))\n",
    "    plt.title('k,s grid search for up to k neighbors for cluster ' + str(clid),fontsize=20)\n",
    "    #ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    plt.contourf(X,Y,cluster_grid_r2)\n",
    "    plt.ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    plt.xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    #ax.set_title('Cluster '+ clid )\n",
    "    plt.show()\n",
    "#plt.savefig(FIG_DIR+'cluster_ksgrid_uptok')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster_grid_r2s.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "i=1\n",
    "fig=plt.figure(figsize=(12,300))\n",
    "for clid,cluster_grid_r2 in exactk_cluster_grid_r2s.iteritems():\n",
    "    fig.suptitle('k,s grid search for exactly k neighbors',fontsize=20)\n",
    "    ax=fig.add_subplot(2,50,i,projection='3d')\n",
    "    #ax.text2D(.5,.95,'Global',transform=ax.transAxes,fontsize=20)\n",
    "    X,Y=np.meshgrid(ss,ks)\n",
    "    i+=1\n",
    "    ax.plot_surface(X,Y,cluster_grid_r2)\n",
    "    ax.set_ylabel('Maximum number of neighbors (k)',fontsize=16)\n",
    "    ax.set_xlabel('Similarity threshold (s)',fontsize=16)\n",
    "    ax.set_zlabel('R2')\n",
    "    ax.set_title('Cluster '+ clid )\n",
    "plt.subplots.adjust()\n",
    "plt.savefig(FIG_DIR+'cluster_ksgrid_exactk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EPA Categories Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors=pd.read_csv(DAT_DIR+'category_neighbors_chemotypes.csv')\n",
    "category_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions=pd.read_csv(DAT_DIR+'category_predictions_chemotypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Category Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=category_predictions[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "search_spaces=pickle.load(open(DAT_DIR+'search_spaces.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category,search_space in search_spaces.iteritems():\n",
    "    if len(search_space)>=20:\n",
    "        df=category_predictions.loc[search_space][['systemic','systemic_p']]\n",
    "        df=df[df.notnull().all(axis='columns')]\n",
    "        df=df[(df!=np.inf).all(axis=1)]\n",
    "        plt.scatter(df['systemic'],df['systemic_p'])\n",
    "        plt.title(str(category) + ' systemic LOAEL predictions')\n",
    "        plt.xlabel('True')\n",
    "        plt.ylabel('Predicted')\n",
    "        range_setter='systemic'\n",
    "        if (max(df['systemic_p'])-min(df['systemic_p']))>(max(df['systemic'])-min(df['systemic'])):\n",
    "            range_setter=range_setter+'_p'\n",
    "        plt.xlim(min(df[range_setter])-.01,max(df[range_setter])+.01)\n",
    "        plt.ylim(min(df[range_setter])-.01,max(df[range_setter])+.01)\n",
    "        plt.annotate('R2='+str(round(r2_score(df['systemic'],df['systemic_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "        plt.annotate('n='+str(len(search_space)),xy=(.03,.88),xycoords='axes fraction')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
