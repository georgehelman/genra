{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import sys\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "TOP = '/'.join(os.getcwd().split('/')[:-2])+'/'\n",
    "LIB = TOP+'lib'\n",
    "if not LIB in sys.path: \n",
    "    sys.path.insert(0,LIB)\n",
    "\n",
    "DAT_DIR = TOP + 'data/toxref/'\n",
    "FIG_DIR = TOP + 'figs/toxref/'\n",
    "\n",
    "from rax.genrapred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongocon=pymongo.MongoClient(\"mongodb://ghelman:ghelman@pb.epa.gov/genra_dev_v4\")\n",
    "DB=mongocon['genra_dev_v4']\n",
    "dsstox=DB['compound']\n",
    "toxref=DB['toxrefdb2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worthy(pdobject):\n",
    "    if isinstance(pdobject,pd.core.series.Series):\n",
    "        pdobject=pdobject[pd.notnull(pdobject)]\n",
    "        pdobject=pdobject[pdobject!=np.inf]\n",
    "        return pdobject\n",
    "    elif isinstance(pdobject,pd.core.frame.DataFrame):\n",
    "        pdobject=pdobject[pdobject.notnull().all(axis='columns')]\n",
    "        pdobject=pdobject[(pdobject!=np.inf).all(axis=1)]\n",
    "        return pdobject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_k_wtavg(df,name,k,s):\n",
    "    df=df[df['jaccard']>s]\n",
    "    df=df[df[name]!=np.inf]\n",
    "    df=df[df[name].notnull()].iloc[0:k]\n",
    "    if len(df)<k:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return np.average(values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtvar(df,name,k):\n",
    "    df=df[(df[name].notnull()) & (df[name]!=np.inf)].iloc[0:k]\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    weights=list(df['jaccard'])\n",
    "    values=list(df[name])\n",
    "    return sum([weights[i]**2*values[i] for i in range(len(values))])/sum(weights)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_df=pd.read_csv(DAT_DIR+'loael.csv')\n",
    "lel_df=pd.read_csv(DAT_DIR+'lel.csv')\n",
    "loael_agg=pd.read_csv(DAT_DIR+'loaelagg.csv',index_col='dsstox_sid')\n",
    "lel_agg=pd.read_csv(DAT_DIR+'lelagg.csv',index_col='dsstox_sid')\n",
    "loael_sids=list(set(loael_agg.index.values))\n",
    "lel_sids=list(set(lel_agg.index.values))\n",
    "loael_neighbors=pd.read_csv(DAT_DIR+'loael_neighbors_mrgn.csv')\n",
    "loael_predictions=pd.read_csv(DAT_DIR+'loael_predictions_mrgn.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "ks=range(1,20)\n",
    "ss=[round(s/20,2) for s in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=list(loael_agg.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mean Aggregation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loael_agg_mean=pd.read_csv(DAT_DIR+'loael_agg_mean_mrgn.csv',index_col='dsstox_sid')\n",
    "loael_agg_sd=pd.read_csv(DAT_DIR+'loael_agg_sd_mrgn.csv',index_col='dsstox_sid')\n",
    "loael_neighbors_mean=pd.read_csv(DAT_DIR+'loael_neighbors_mean_mrgn.csv',index_col=0)\n",
    "loael_neighbors_sd=pd.read_csv(DAT_DIR+'loael_neighbors_sd_mrgn.csv',index_col=0)\n",
    "loael_predictions_mean=pd.read_csv(DAT_DIR+'loael_predictions_mean_mrgn.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global R2 for all endpoint categories\n",
    "from sklearn.metrics import r2_score\n",
    "stacked_df=pd.DataFrame()\n",
    "for category in categories:\n",
    "    cat_df=loael_predictions_mean[[category,category+'_p']]\n",
    "    cat_df=cat_df.rename(columns={category:'true',category+'_p':'predicted'})\n",
    "    stacked_df=stacked_df.append(cat_df)\n",
    "stacked_df=plot_worthy(stacked_df)\n",
    "r2_score(stacked_df['true'],stacked_df['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Mean Aggregation Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=loael_predictions_mean[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.9),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genra_predict(ndf,tdf,category,k,s):\n",
    "    predictions={}\n",
    "    for sid,group in ndf.groupby(['target_sid']):\n",
    "        predictions[sid]=wtavg(group,category,k,s)\n",
    "    prediction_df=pd.DataFrame(predictions.values(),index=predictions.keys(),columns=[category+'_p'])\n",
    "    prediction_df=prediction_df.merge(tdf,right_index=True,left_index=True)\n",
    "    prediction_df=prediction_df[[category,category+'_p']]\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids=loael_neighbors['target_sid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "r2s={}\n",
    "k=10\n",
    "s=.05\n",
    "for category in categories:\n",
    "    i=0\n",
    "    r2s[category]=[]\n",
    "    while i<100:\n",
    "        train,test=train_test_split(sids,test_size=.1)\n",
    "        test_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(test))]\n",
    "        \n",
    "        tts_predictions=plot_worthy(genra_predict(test_neighbors,loael_agg,category,k,s))\n",
    "        r2s[category].append(r2_score(tts_predictions[category],tts_predictions[category+'_p']))\n",
    "        i+=1\n",
    "min_r2s=pd.DataFrame([{'category':category,'mean':np.mean(r2list),'sd':np.std(r2list)} for category,r2list in r2s.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "r2s={}\n",
    "k=10\n",
    "s=.05\n",
    "for category in categories:\n",
    "    i=0\n",
    "    r2s[category]=[]\n",
    "    while i<100:\n",
    "        train,test=train_test_split(sids,test_size=.1)\n",
    "        test_neighbors=loael_neighbors_mean[(loael_neighbors_mean['neighbor_sid'].isin(train)) & (loael_neighbors_mean['target_sid'].isin(test))]\n",
    "        tts_predictions=plot_worthy(genra_predict(test_neighbors,loael_agg_mean,category,k,s))\n",
    "        r2s[category].append(r2_score(tts_predictions[category],tts_predictions[category+'_p']))\n",
    "        i+=1\n",
    "mean_r2s=pd.DataFrame([{'category':category,'mean':np.mean(r2list),'sd':np.std(r2list)} for category,r2list in r2s.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_r2s['agg']='min'\n",
    "mean_r2s['agg']='mean'\n",
    "pd.concat([min_r2s,mean_r2s])\n",
    "#pd.concat([min_r2s,mean_r2s]).to_csv('r2s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,2,figsize=(10,10))\n",
    "fig.suptitle('R2 scores for 100 90-10 train-test splits')\n",
    "ax=ax.reshape(-1)\n",
    "for category, r2list in r2s.iteritems():\n",
    "    axes,ax=ax[0],ax[1:]\n",
    "    sns.distplot(r2list,ax=axes)\n",
    "    df=loael_predictions_mean[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    axes.axvline(x=r2_score(df[category],df[category+'_p']),color='orange',label='Full Dataset')\n",
    "    axes.set_xlabel('R2 score')\n",
    "    axes.set_title(category)\n",
    "    axes.legend(loc='best',fontsize=11)\n",
    "    axes.annotate('Mean='+str(round(np.mean(r2list),2)),xy=(.03,.85),xycoords='axes fraction')\n",
    "    axes.annotate('SD='+str(round(np.std(r2list),2)),xy=(.03,.8),xycoords='axes fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "percents=[n*.01 for n in range(1,26,1)]\n",
    "train_r2s=[]\n",
    "test_r2s=[]\n",
    "k=10\n",
    "s=.05\n",
    "for percent in percents:\n",
    "    train,test=train_test_split(sids,test_size=percent)\n",
    "    test_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(test))]\n",
    "    train_neighbors=loael_neighbors[(loael_neighbors['neighbor_sid'].isin(train)) & (loael_neighbors['target_sid'].isin(train))]\n",
    "    \n",
    "    category='systemic'\n",
    "    test_df=plot_worthy(genra_predict(test_neighbors,loael_agg,category,k,s))\n",
    "    train_df=plot_worthy(genra_predict(train_neighbors,loael_agg,category,k,s))\n",
    "    test_r2s.append(r2_score(test_df[category],test_df[category+'_p']))\n",
    "    train_r2s.append(r2_score(train_df[category],train_df[category+'_p']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(percents,test_r2s,label='test R2')\n",
    "ax.plot(percents,train_r2s,label='train R2')\n",
    "df=plot_worthy(loael_predictions[['systemic','systemic_p']])\n",
    "base_r2=r2_score(df['systemic'],df['systemic_p'])\n",
    "ax.axhline(y=base_r2,label='base R2',ls='--',color='black')\n",
    "ax.set_title('Learning Curve (Systemic)')\n",
    "ax.set_xlabel('Percent test set')\n",
    "ax.set_ylabel('R2')\n",
    "ax.legend(loc=0)\n",
    "plt.savefig(FIG_DIR+'learning_curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EPA Categories Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors=pd.read_csv(DAT_DIR+'category_neighbors_mrgn.csv')\n",
    "category_neighbors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions=pd.read_csv(DAT_DIR+'category_predictions_mrgn.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "i=1\n",
    "f=plt.figure(figsize=(12,12))\n",
    "f.suptitle('Category Predictions')\n",
    "for category in categories:\n",
    "    plt.subplot(2,2,i)\n",
    "    i+=1\n",
    "    df=category_predictions[[category,category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    plt.scatter(df[category],df[category+'_p'])\n",
    "    plt.title(category+ ' LOAEL Predictions')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.annotate('R2='+str(round(r2_score(df[category],df[category+'_p']),2)),xy=(.03,.93),xycoords='axes fraction')\n",
    "plt.subplots_adjust(wspace=.5,hspace=.4)\n",
    "plt.savefig(FIG_DIR+'example_fit_categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EPA Category Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_sids=category_neighbors['target_sid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "epa_r2s={}\n",
    "for endpoint_category in categories:\n",
    "    i=0\n",
    "    epa_r2s[endpoint_category]=[]\n",
    "    while i<100:\n",
    "        train,test=train_test_split(epa_sids,test_size=.1)\n",
    "        test_neighbors=category_neighbors[(category_neighbors['neighbor_sid'].isin(train)) & (category_neighbors['target_sid'].isin(test))]\n",
    "        k=10\n",
    "        s=.05\n",
    "        tts_predictions=plot_worthy(genra_predict(test_neighbors,loael_agg,endpoint_category,k,s))\n",
    "        epa_r2s[endpoint_category].append(r2_score(tts_predictions[endpoint_category],tts_predictions[endpoint_category+'_p']))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,2,figsize=(10,10))\n",
    "fig.suptitle('R2 scores for 100 90-10 train-test splits')\n",
    "ax=ax.reshape(-1)\n",
    "for endpoint_category, r2list in epa_r2s.iteritems():\n",
    "    axes,ax=ax[0],ax[1:]\n",
    "    sns.distplot(r2list,ax=axes)\n",
    "    df=category_predictions[[endpoint_category,endpoint_category+'_p']]\n",
    "    df=df[df.notnull().all(axis='columns')]\n",
    "    df=df[(df!=np.inf).all(axis=1)]\n",
    "    axes.axvline(x=r2_score(df[endpoint_category],df[endpoint_category+'_p']),color='orange',label='Full Dataset')\n",
    "    axes.set_xlabel('R2 score')\n",
    "    axes.set_title(endpoint_category)\n",
    "    axes.legend(loc='best',fontsize=11)\n",
    "    axes.annotate('Mean='+str(round(np.mean(r2list),2)),xy=(.03,.85),xycoords='axes fraction')\n",
    "    axes.annotate('SD='+str(round(np.std(r2list),2)),xy=(.03,.8),xycoords='axes fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "search_spaces=pickle.load(open(DAT_DIR+'search_spaces.pkl'))\n",
    "search_spaces={str(k):v for k,v in search_spaces.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The following categories have 10 or more members')\n",
    "[(category,len(search_space)) for category,search_space in search_spaces.iteritems() if len(search_space)>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_r2s={}\n",
    "k=10\n",
    "s=.05\n",
    "for epa_category,search_space in search_spaces.iteritems():\n",
    "    category_r2s[epa_category]={}\n",
    "    epa_category_agg=loael_agg.loc[search_spaces[epa_category]]\n",
    "    for endpoint_category in categories:\n",
    "        i=0\n",
    "        category_r2s[epa_category][endpoint_category]=[]\n",
    "        epa_category_endpoint_agg=plot_worthy(epa_category_agg[endpoint_category])\n",
    "        neighborhood_sids=list(epa_category_endpoint_agg.index)    \n",
    "        if len(neighborhood_sids)<5:\n",
    "            continue\n",
    "        while i<100:\n",
    "            test_set_size=max(.1,2/len(neighborhood_sids)) #Ensures atleast 2 chemicals in test set\n",
    "            train,test=train_test_split(neighborhood_sids, test_size=test_set_size)\n",
    "            test_neighbors=loael_neighbors[(loael_neighbors['target_sid'].isin(test)) & loael_neighbors['neighbor_sid'].isin(train)]\n",
    "            tts_predictions=plot_worthy(genra_predict(test_neighbors,loael_agg,endpoint_category,k,s))\n",
    "            category_r2s[epa_category][endpoint_category].append(r2_score(tts_predictions[endpoint_category],tts_predictions[endpoint_category+'_p']))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsstox_category_counts=pd.read_csv(DAT_DIR+'dsstox_epa_categories.csv',index_col=0)\n",
    "from ast import literal_eval\n",
    "dsstox_counts={literal_eval(k):v for k,v in dsstox_category_counts.to_dict()['categories'].iteritems()} #lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Summary Table</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# records=[]\n",
    "# for epa_category,search_space in search_spaces.iteritems():\n",
    "#     if len(search_space)<5:\n",
    "#         continue\n",
    "#     row={'category':epa_category,\n",
    "#         'dsstox_size':dsstox_counts[epa_category],\n",
    "#         'toxref_size':len(search_space),\n",
    "#         'jaccard_sd':category_neighbors[(category_neighbors['target_sid'].isin(search_space)) & category_neighbors['neighbor_sid'].isin(search_space)]['jaccard'].std()\n",
    "#         }\n",
    "#     for endpoint_category in categories:\n",
    "#         row[endpoint_category+'_r2_mean']=np.mean(category_r2s[epa_category][endpoint_category])\n",
    "#         row[endpoint_category+'_r2_sd']=np.std(category_r2s[epa_category][endpoint_category])\n",
    "#     records.append(row)\n",
    "# df102218=pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df102218=pd.DataFrame(records)\n",
    "# df102218=df102218.loc[:,['category','toxref_size','coverage','dsstox_size','size_ratio','jaccard_mean','jaccard_sd']\\\n",
    "#                       +list(sum(zip([category+'_r2_mean' for category in categories],[category+'_r2_sd' for category in categories]),()))]\n",
    "# df102218\n",
    "# df102218.to_csv(DAT_DIR+'102218_df.csv')\n",
    "df102218=pd.read_csv(DAT_DIR+'102218_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Example Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def av_sim(ser):\n",
    "    ser=ser.iloc[0:2]\n",
    "    return np.mean(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt9=loael_neighbors_mean[loael_neighbors_mean['jaccard']>.9]['target_sid'].unique()\n",
    "print(str(len(gt9)) + ' of '+ str(len(loael_neighbors_mean['target_sid'].unique())) + ' chemicals have atleast 1 neighbor with similarity > .9')\n",
    "av_sims=loael_neighbors_mean.pivot_table(index='target_sid',values='jaccard',aggfunc=av_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(series):\n",
    "    diff=[abs(series[category]-series[category+'_p']) for category in categories if not np.isnan(series[category])]\n",
    "    return sum(diff)/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loael best results\n",
    "ranked_loaels=loael_predictions_mean.copy()\n",
    "ranked_loaels['rank']=ranked_loaels.apply(ranker,axis='columns')\n",
    "#ranked_loaels=ranked_loaels.loc[gt9]\n",
    "av_sims=loael_neighbors_mean.pivot_table(index='target_sid',values='jaccard',aggfunc=av_sim)\n",
    "ranked_loaels['av_sim']=ranked_loaels.index.map(av_sims.squeeze())\n",
    "weights={record['dsstox_sid']:record['mol_weight'] for record in dsstox.find({'dsstox_sid':{'$in':loael_sids}})}\n",
    "ranked_loaels['mol_weight']=ranked_loaels.index.map(weights)\n",
    "ranked_loaels=ranked_loaels.sort_values('av_sim',ascending=False)\n",
    "ranked_loaels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_loaels=ranked_loaels.sort_values('rank')\n",
    "ranked_loaels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_sims=ranked_loaels[ranked_loaels['av_sim']>.7].sort_values('rank')\n",
    "high_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('High sim low residual: ' + ', '.join(list(high_sims.index[0:4])))\n",
    "print('High sim high residual: ' + ', '.join(list(high_sims.index[-2:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back(lm,weight):\n",
    "    return 10**-lm*1000*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good prediction\n",
    "sid='DTXSID7037555'\n",
    "print('Name: ' + dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})['name'] + '\\n')\n",
    "print('Average similarity of first 2 neighbors: ' + str(ranked_loaels.loc[sid]['av_sim']) + '\\n')\n",
    "row=loael_predictions_mean.loc[sid]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['systemic']))].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad prediction\n",
    "sid='DTXSID5031131'\n",
    "print('Name: ' + dsstox.find_one({'dsstox_sid':sid},{'_id':0,'name':1})['name'] + '\\n')\n",
    "print('Average similarity of first 2 neighbors: ' + str(ranked_loaels.loc[sid]['av_sim']) + '\\n')\n",
    "row=loael_predictions_mean.loc[sid]\n",
    "print('Predictions')\n",
    "row[[category+'_p' for category in categories]]\n",
    "print('Measured')\n",
    "row[categories]\n",
    "print('mg/kg Predictions')\n",
    "[{category:convert_back(row[category+'_p'],weights[sid]) for category in categories}]\n",
    "print('mg/kg Measured')\n",
    "[{category:convert_back(row[category],weights[sid]) for category in categories}]\n",
    "loael_neighbors[(loael_neighbors['target_sid']==sid) & (pd.notnull(loael_neighbors['systemic']))].iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Clustering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps=getFP(list(sids),DB=DB)\n",
    "fps=fps.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=linkage(fps,'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, coph_dists = cophenet(Z,pdist(fps))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "epa_categories=pickle.load(open(DAT_DIR+'search_spaces.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters={}\n",
    "for category, search_space in epa_categories.iteritems():\n",
    "    if len(search_space)<10:\n",
    "        continue\n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.title(str(category) + ' hierarchical clustering')\n",
    "    category_fps=getFP(search_space,DB=DB)\n",
    "    category_fps=category_fps.fillna(0)\n",
    "    clustering=linkage(category_fps,method='ward',metric='jaccard')\n",
    "    max_d=max(clustering[:,2])*.7 #Default cluster cutoff in dendrogram function\n",
    "    dendrogram(clustering,show_contracted=True)\n",
    "    plt.annotate(str(len(search_space)) + ' total chemicals', xy=(.005,.97),xycoords='axes fraction')\n",
    "    plt.savefig(FIG_DIR+'dendrograms/'+str(category))\n",
    "    clusters[category]=fcluster(clustering,max_d,criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import math\n",
    "for category,subcategory_ids in clusters.iteritems():\n",
    "    search_space=epa_categories[category]\n",
    "    sub_ids=set(subcategory_ids)\n",
    "    for sub_id in sub_ids:\n",
    "        subcategory=[search_space[i] for i,x in enumerate(subcategory_ids) if x==sub_id]\n",
    "        mols=[Chem.MolFromSmiles(record['smiles']) for record in dsstox.find({'dsstox_sid':{'$in':subcategory}})]\n",
    "        if not category==() or not sub_id==1:\n",
    "            continue\n",
    "        if category==() and sub_id==1:\n",
    "            mols=mols[1:21]+mols[23:130]+mols[140:len(mols)] #Some in those ranges don't work and break the whole thing\n",
    "        svg=Draw._MolsToGridSVG(mols,molsPerRow=int(math.ceil(np.sqrt(len(mols)))))\n",
    "        with open(FIG_DIR+'subclusters'+'/'+str(category)+'_'+str(sub_id)+'.svg','w') as f:\n",
    "            f.write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Additions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_map={}\n",
    "for category,search_space in search_spaces.iteritems():\n",
    "    for chem in search_space:\n",
    "        cat_map[chem]=str(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_loaels['EPA category']=ranked_loaels.index.map(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame()\n",
    "for endpoint_category in categories:\n",
    "    res_df[endpoint_category]=abs(category_predictions[endpoint_category]-category_predictions[endpoint_category+'_p'])\n",
    "res_df=res_df.reset_index()\n",
    "res_df=pd.melt(res_df,id_vars='index',var_name='endpoint_category',value_name='residual')\n",
    "res_df=res_df.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category,search_space in search_spaces.iteritems():\n",
    "    if len(search_space)<10:\n",
    "        continue\n",
    "    cat_df=res_df.loc[search_space]\n",
    "    sns.boxplot(x='endpoint_category',y='residual',data=cat_df)\n",
    "    plt.title(category)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multineighbor(s):\n",
    "    return True if len(s)>1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows=[]\n",
    "for i,row in df102218.iterrows():\n",
    "    epa_category=row['category']\n",
    "    search_space=search_spaces[epa_category]\n",
    "    temp_df=ranked_loaels[ranked_loaels['EPA category']==epa_category]\n",
    "    row['coverage']=category_neighbors[(category_neighbors['target_sid'].isin(search_space)) \\\n",
    "                                       & (category_neighbors['neighbor_sid'].isin(search_space))].pivot_table(\n",
    "                                        index='target_sid',values='neighbor_sid',aggfunc=multineighbor).sum().values[0]\n",
    "    row['5th_percentile']=np.percentile(temp_df['rank'],5)\n",
    "    row['median']=np.percentile(temp_df['rank'],50)\n",
    "    row['95th_percentile']=np.percentile(temp_df['rank'],95)\n",
    "    new_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df102218=pd.DataFrame(new_rows)\n",
    "df102218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=category_neighbors.pivot_table(index='target_sid',values='neighbor_sid',aggfunc=multineighbor)\n",
    "b=[sid for sid,boo in a.iterrows() if not boo['neighbor_sid']]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_neighbors[(category_neighbors['target_sid'].isin(b))]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
